{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMdPBnv/6kqkQKnZEfqRkFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14fa7abfb7ba40a283d7ba9aedf0a4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_155c0413b250422ba44ce8f648254147",
              "IPY_MODEL_68245efa3b9b451da46d13585af13faf",
              "IPY_MODEL_db101fa9194d45688fa8ecd0ffbef07c"
            ],
            "layout": "IPY_MODEL_b52997378fc141dcbc5338c5546b0c72"
          }
        },
        "155c0413b250422ba44ce8f648254147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69bb94ec62fe4cfdb3d524c6b823d48b",
            "placeholder": "​",
            "style": "IPY_MODEL_d5e8253fb6cb44878641d9f4f1fe2d37",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "68245efa3b9b451da46d13585af13faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f09bb02580b341659291531140ddfa5d",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3d3e998d1434c429a664834e8a5f9ec",
            "value": 49
          }
        },
        "db101fa9194d45688fa8ecd0ffbef07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5126e8d00ef4451a79085c36ae837b5",
            "placeholder": "​",
            "style": "IPY_MODEL_aae000c90c3b4be8bdc8e5b4135bde39",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.41kB/s]"
          }
        },
        "b52997378fc141dcbc5338c5546b0c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69bb94ec62fe4cfdb3d524c6b823d48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e8253fb6cb44878641d9f4f1fe2d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f09bb02580b341659291531140ddfa5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d3e998d1434c429a664834e8a5f9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5126e8d00ef4451a79085c36ae837b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae000c90c3b4be8bdc8e5b4135bde39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72181cc815fb42bfa619eb4ee6ca9b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16781fed44ca4dbeb88442593e65ac55",
              "IPY_MODEL_d724947126304f35ba1044425c9654fa",
              "IPY_MODEL_01df8ddab8d24ee3af0c9cfbafa53a84"
            ],
            "layout": "IPY_MODEL_19d33a0aba4540209c728867c291773e"
          }
        },
        "16781fed44ca4dbeb88442593e65ac55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df84f1d5af174feab5d0c57cd65e9017",
            "placeholder": "​",
            "style": "IPY_MODEL_1b95fe8a647f48fabfd49bf19fe6886c",
            "value": "config.json: 100%"
          }
        },
        "d724947126304f35ba1044425c9654fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec455578c2642f98a542d1f5cad061b",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_998578ee421e47edad3889f96e163bd9",
            "value": 570
          }
        },
        "01df8ddab8d24ee3af0c9cfbafa53a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e703bf7d0eeb4c5ea3741dc5105048a9",
            "placeholder": "​",
            "style": "IPY_MODEL_e3219fcec0d74c3da75e430aedccff1c",
            "value": " 570/570 [00:00&lt;00:00, 47.5kB/s]"
          }
        },
        "19d33a0aba4540209c728867c291773e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df84f1d5af174feab5d0c57cd65e9017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b95fe8a647f48fabfd49bf19fe6886c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec455578c2642f98a542d1f5cad061b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998578ee421e47edad3889f96e163bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e703bf7d0eeb4c5ea3741dc5105048a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3219fcec0d74c3da75e430aedccff1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a31dd9e9ce1a4b5384507d0a0396a241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a51f7ae7fbd441be90f55735a18b294d",
              "IPY_MODEL_42b6c3a19a944cfe81f0d57fb234be29",
              "IPY_MODEL_0de524f43bbf4873ad680b94408157ec"
            ],
            "layout": "IPY_MODEL_7ac826ec4eb24842a309e8332123d97f"
          }
        },
        "a51f7ae7fbd441be90f55735a18b294d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a199586ded34cb3bf1dcb305bcaa6e6",
            "placeholder": "​",
            "style": "IPY_MODEL_9ee59eae36f440aa99fa19eb32dd7832",
            "value": "vocab.txt: 100%"
          }
        },
        "42b6c3a19a944cfe81f0d57fb234be29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_990cbddad13b4e91a239f9d08f6a6c00",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e6b766cdd0b446faf8ab30d3efee735",
            "value": 213450
          }
        },
        "0de524f43bbf4873ad680b94408157ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e520e7ef2b64488eb9c78d89d2ea5d2e",
            "placeholder": "​",
            "style": "IPY_MODEL_00ca6650934242539cba888ca4a8b133",
            "value": " 213k/213k [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "7ac826ec4eb24842a309e8332123d97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a199586ded34cb3bf1dcb305bcaa6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee59eae36f440aa99fa19eb32dd7832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990cbddad13b4e91a239f9d08f6a6c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6b766cdd0b446faf8ab30d3efee735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e520e7ef2b64488eb9c78d89d2ea5d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ca6650934242539cba888ca4a8b133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60a7e62090fd445f9e3c7c9b6d060696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d01e5855e854035ac9659aa42145faf",
              "IPY_MODEL_89a23d04913c414ca3014b222a13dc19",
              "IPY_MODEL_2a04a8154431416ab71c22917749b16b"
            ],
            "layout": "IPY_MODEL_4a33aa803c2c4a61aa079120cc73b919"
          }
        },
        "6d01e5855e854035ac9659aa42145faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_953cdb9e34504de5a4b94140151fd6e0",
            "placeholder": "​",
            "style": "IPY_MODEL_9bbcf5df54504dc3be6a102256763c9d",
            "value": "tokenizer.json: 100%"
          }
        },
        "89a23d04913c414ca3014b222a13dc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9cb4abee9dc4134abff9a42b26307d8",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bcce7ce6b364a1992868a1ab8ee13bc",
            "value": 435797
          }
        },
        "2a04a8154431416ab71c22917749b16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15a8c7115cd40f9bc519923870dee86",
            "placeholder": "​",
            "style": "IPY_MODEL_32bc5a3554a04094bec7fdb3c7212c0b",
            "value": " 436k/436k [00:00&lt;00:00, 1.90MB/s]"
          }
        },
        "4a33aa803c2c4a61aa079120cc73b919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953cdb9e34504de5a4b94140151fd6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bbcf5df54504dc3be6a102256763c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9cb4abee9dc4134abff9a42b26307d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bcce7ce6b364a1992868a1ab8ee13bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e15a8c7115cd40f9bc519923870dee86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bc5a3554a04094bec7fdb3c7212c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea2476c889a84a28bda8d5cb807c8034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a210e85992ad4b2ea1fb2292dbd273bb",
              "IPY_MODEL_13a22b106a624a0ca28e257d14927e09",
              "IPY_MODEL_1236bce666d9455ea5c6078b67e8ec56"
            ],
            "layout": "IPY_MODEL_616eb1f4788a4d3a828a9c440f740d15"
          }
        },
        "a210e85992ad4b2ea1fb2292dbd273bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1401e24ca220466b80a0e230b2de0d18",
            "placeholder": "​",
            "style": "IPY_MODEL_176ae11ef37749008314891ff99ce4d2",
            "value": "model.safetensors: 100%"
          }
        },
        "13a22b106a624a0ca28e257d14927e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44f2f4e096a43a191350d9df0afaebd",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a66497a2200b41618f0f818a476bb556",
            "value": 435755784
          }
        },
        "1236bce666d9455ea5c6078b67e8ec56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c65089faaa4d488c35f5f207f0f499",
            "placeholder": "​",
            "style": "IPY_MODEL_8992fb182ac04c86a546b98a33cf27c1",
            "value": " 436M/436M [00:01&lt;00:00, 404MB/s]"
          }
        },
        "616eb1f4788a4d3a828a9c440f740d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1401e24ca220466b80a0e230b2de0d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176ae11ef37749008314891ff99ce4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44f2f4e096a43a191350d9df0afaebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66497a2200b41618f0f818a476bb556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18c65089faaa4d488c35f5f207f0f499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8992fb182ac04c86a546b98a33cf27c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4154e7b81b4c48428e83e1441fe2f3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bfc5abf395c45458037929e837a77c5",
              "IPY_MODEL_7070c25430e64c8e893f6cd68ada9185",
              "IPY_MODEL_0e71e9a575d545dd82bd99a7a7ee3946"
            ],
            "layout": "IPY_MODEL_24db1e04f7e5461f848e56261080e882"
          }
        },
        "9bfc5abf395c45458037929e837a77c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb1d000b44a4624b39b31ec29bbe8fb",
            "placeholder": "​",
            "style": "IPY_MODEL_b29eccae8663406a974e794a684e8981",
            "value": "Map: 100%"
          }
        },
        "7070c25430e64c8e893f6cd68ada9185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5855b890d7bd42dba37a78a41f73dc2e",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb3547825b2c417f823524d6e83529a2",
            "value": 20000
          }
        },
        "0e71e9a575d545dd82bd99a7a7ee3946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff0dc61cbd343318133e7d0de2c0f50",
            "placeholder": "​",
            "style": "IPY_MODEL_a4cca4ca303843dd8dd8008ebb9d11aa",
            "value": " 20000/20000 [00:17&lt;00:00, 1206.29 examples/s]"
          }
        },
        "24db1e04f7e5461f848e56261080e882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb1d000b44a4624b39b31ec29bbe8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29eccae8663406a974e794a684e8981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5855b890d7bd42dba37a78a41f73dc2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb3547825b2c417f823524d6e83529a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bff0dc61cbd343318133e7d0de2c0f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cca4ca303843dd8dd8008ebb9d11aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843973f29d4d4bfc9c5eb54bcd8abe79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e74e3f9a68141e2b0c422403d24f605",
              "IPY_MODEL_40b3172ecb3040d092d4140d9f514d6a",
              "IPY_MODEL_108098b06cd449bd8164170698665e18"
            ],
            "layout": "IPY_MODEL_f6f6379f83ad4a1fa30fc13e80a89e39"
          }
        },
        "9e74e3f9a68141e2b0c422403d24f605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f08d5208149d4e7ebc97d2c3a07310c7",
            "placeholder": "​",
            "style": "IPY_MODEL_30e728826b9d49bf9e771a3f95c1c38b",
            "value": "Map: 100%"
          }
        },
        "40b3172ecb3040d092d4140d9f514d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b10b2c4713b54ddc825c240515e3baed",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1aaff65c5f7456f9cd4d4591aa0e6bc",
            "value": 20000
          }
        },
        "108098b06cd449bd8164170698665e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e277ae80d8564c5c92d3806f4cde790b",
            "placeholder": "​",
            "style": "IPY_MODEL_bffd6e613ec74c5593c4cca484645a54",
            "value": " 20000/20000 [00:12&lt;00:00, 1561.38 examples/s]"
          }
        },
        "f6f6379f83ad4a1fa30fc13e80a89e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08d5208149d4e7ebc97d2c3a07310c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e728826b9d49bf9e771a3f95c1c38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10b2c4713b54ddc825c240515e3baed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1aaff65c5f7456f9cd4d4591aa0e6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e277ae80d8564c5c92d3806f4cde790b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bffd6e613ec74c5593c4cca484645a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0edde7206535445d9589c72255846b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fccca33abf2e4e15a2b12c613343e523",
              "IPY_MODEL_73f392e8a3594598af7f996750d218d5",
              "IPY_MODEL_893733fa7b064799af79c7510ff8e334"
            ],
            "layout": "IPY_MODEL_fce9f6932ddf42998ad7cad6bf5cc606"
          }
        },
        "fccca33abf2e4e15a2b12c613343e523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2970c4e4ce204d2caaa5c4b21257f765",
            "placeholder": "​",
            "style": "IPY_MODEL_cce02c855c994afb890a1a57b46c42bc",
            "value": "Map: 100%"
          }
        },
        "73f392e8a3594598af7f996750d218d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad4a428b5f04f1c8b8081d3a736665e",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dc12de6efb6445fa12eec34e700f297",
            "value": 20000
          }
        },
        "893733fa7b064799af79c7510ff8e334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6270e47347194675ab51e77181e70aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_2071cf91c8154f1f92613ee83ab72cf3",
            "value": " 20000/20000 [00:24&lt;00:00, 829.36 examples/s]"
          }
        },
        "fce9f6932ddf42998ad7cad6bf5cc606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2970c4e4ce204d2caaa5c4b21257f765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce02c855c994afb890a1a57b46c42bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ad4a428b5f04f1c8b8081d3a736665e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc12de6efb6445fa12eec34e700f297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6270e47347194675ab51e77181e70aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2071cf91c8154f1f92613ee83ab72cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nainakader/notebooks/blob/master/BERT_TESSERACT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGxaC-7XoNBS",
        "outputId": "00d89c39-0e93-4ab0-f6af-af54ab198711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Initialize the Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define patterns for CIVIL NUMBER and DATE OF BIRTH\n",
        "pattern_civil_number = [{'LOWER': 'civil'}, {'LOWER': 'number'}, {'IS_DIGIT': True}]\n",
        "pattern_dob = [{'LOWER': 'date'}, {'LOWER': 'of'}, {'LOWER': 'birth'}, {'IS_DIGIT': True}, {'IS_PUNCT': True}, {'IS_DIGIT': True}, {'IS_PUNCT': True}, {'IS_DIGIT': True}]\n",
        "\n",
        "# Add patterns to the matcher\n",
        "matcher.add('CIVIL_NUMBER', [pattern_civil_number])\n",
        "matcher.add('DOB', [pattern_dob])\n",
        "\n",
        "# Sample text\n",
        "sample_text = \"\"\"\n",
        "8? fit ft eke \\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Function to extract information\n",
        "def extract_info(text):\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    civil_number = 'Not Found'\n",
        "    date_of_birth = 'Not Found'\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        if doc.vocab.strings[match_id] == 'CIVIL_NUMBER':\n",
        "            civil_number = span[-1].text  # Last token is the number\n",
        "        elif doc.vocab.strings[match_id] == 'DOB':\n",
        "            date_of_birth = span[-3:].text_with_ws.strip()  # Last three tokens for date\n",
        "\n",
        "    return civil_number, date_of_birth\n",
        "\n",
        "# Generate dataset\n",
        "data = []\n",
        "for _ in range(20000):\n",
        "    civil_number, date_of_birth = extract_info(sample_text)\n",
        "    data.append({'Sample Text': sample_text, 'Civil Number': civil_number, 'Date of Birth': date_of_birth})\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('extracted_data.csv', index=False)\n",
        "\n",
        "print(\"Dataset generated and saved to 'extracted_data.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iEo1AkjoRZV",
        "outputId": "a0a6964d-b31c-46a9-a4cc-6c5feaf3bfd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated and saved to 'extracted_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9PPCe6RKTZD",
        "outputId": "4d58f613-03f6-4524-e2d0-5083f1c01002"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJj10kn-HOIA",
        "outputId": "dd07d87c-5ea1-4c58-ea67-b8f9f76c903e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9CsUj2uGT6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required libraries\n",
        "#!pip install transformers datasets\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Load the dataset\n",
        "file_path = './resident_card_data_samples_with_junk.csv'  # Replace with the path to your CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Function to label the text\n",
        "def label_text(row):\n",
        "    text = row['Sample Data']\n",
        "    civil_number = str(row['Civil Number'])\n",
        "    date_of_birth = str(row['Date of Birth'])\n",
        "\n",
        "    civil_number_start = text.find(civil_number)\n",
        "    date_of_birth_start = text.find(date_of_birth)\n",
        "\n",
        "    labels = ['O'] * len(text)\n",
        "\n",
        "    if civil_number_start != -1:\n",
        "        for i in range(civil_number_start, civil_number_start + len(civil_number)):\n",
        "            if i == civil_number_start:\n",
        "                labels[i] = 'B-CIVIL_NUMBER'\n",
        "            else:\n",
        "                labels[i] = 'I-CIVIL_NUMBER'\n",
        "\n",
        "    if date_of_birth_start != -1:\n",
        "        for i in range(date_of_birth_start, date_of_birth_start + len(date_of_birth)):\n",
        "            if i == date_of_birth_start:\n",
        "                labels[i] = 'B-DATE_OF_BIRTH'\n",
        "            else:\n",
        "                labels[i] = 'I-DATE_OF_BIRTH'\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Apply the labeling function\n",
        "df['labels'] = df.apply(label_text, axis=1)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased', num_labels=5)  # Adjust num_labels as per your requirement\n",
        "\n",
        "# Define label mapping\n",
        "label_list = ['O', 'B-CIVIL_NUMBER', 'I-CIVIL_NUMBER', 'B-DATE_OF_BIRTH', 'I-DATE_OF_BIRTH']\n",
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples['Sample Data'], truncation=True, padding='max_length', max_length=512)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['labels']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label_map[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label_map[label[word_idx]] if label[word_idx] != 'O' else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Map the tokenization function to the dataset\n",
        "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# Split the dataset into train and test\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': split_dataset['train'],\n",
        "    'test': split_dataset['test']\n",
        "})\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_dict['train'],\n",
        "    eval_dataset=dataset_dict['test'],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('./trained_model')\n",
        "tokenizer.save_pretrained('./trained_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618,
          "referenced_widgets": [
            "14fa7abfb7ba40a283d7ba9aedf0a4f9",
            "155c0413b250422ba44ce8f648254147",
            "68245efa3b9b451da46d13585af13faf",
            "db101fa9194d45688fa8ecd0ffbef07c",
            "b52997378fc141dcbc5338c5546b0c72",
            "69bb94ec62fe4cfdb3d524c6b823d48b",
            "d5e8253fb6cb44878641d9f4f1fe2d37",
            "f09bb02580b341659291531140ddfa5d",
            "c3d3e998d1434c429a664834e8a5f9ec",
            "e5126e8d00ef4451a79085c36ae837b5",
            "aae000c90c3b4be8bdc8e5b4135bde39",
            "72181cc815fb42bfa619eb4ee6ca9b4f",
            "16781fed44ca4dbeb88442593e65ac55",
            "d724947126304f35ba1044425c9654fa",
            "01df8ddab8d24ee3af0c9cfbafa53a84",
            "19d33a0aba4540209c728867c291773e",
            "df84f1d5af174feab5d0c57cd65e9017",
            "1b95fe8a647f48fabfd49bf19fe6886c",
            "aec455578c2642f98a542d1f5cad061b",
            "998578ee421e47edad3889f96e163bd9",
            "e703bf7d0eeb4c5ea3741dc5105048a9",
            "e3219fcec0d74c3da75e430aedccff1c",
            "a31dd9e9ce1a4b5384507d0a0396a241",
            "a51f7ae7fbd441be90f55735a18b294d",
            "42b6c3a19a944cfe81f0d57fb234be29",
            "0de524f43bbf4873ad680b94408157ec",
            "7ac826ec4eb24842a309e8332123d97f",
            "5a199586ded34cb3bf1dcb305bcaa6e6",
            "9ee59eae36f440aa99fa19eb32dd7832",
            "990cbddad13b4e91a239f9d08f6a6c00",
            "4e6b766cdd0b446faf8ab30d3efee735",
            "e520e7ef2b64488eb9c78d89d2ea5d2e",
            "00ca6650934242539cba888ca4a8b133",
            "60a7e62090fd445f9e3c7c9b6d060696",
            "6d01e5855e854035ac9659aa42145faf",
            "89a23d04913c414ca3014b222a13dc19",
            "2a04a8154431416ab71c22917749b16b",
            "4a33aa803c2c4a61aa079120cc73b919",
            "953cdb9e34504de5a4b94140151fd6e0",
            "9bbcf5df54504dc3be6a102256763c9d",
            "f9cb4abee9dc4134abff9a42b26307d8",
            "3bcce7ce6b364a1992868a1ab8ee13bc",
            "e15a8c7115cd40f9bc519923870dee86",
            "32bc5a3554a04094bec7fdb3c7212c0b",
            "ea2476c889a84a28bda8d5cb807c8034",
            "a210e85992ad4b2ea1fb2292dbd273bb",
            "13a22b106a624a0ca28e257d14927e09",
            "1236bce666d9455ea5c6078b67e8ec56",
            "616eb1f4788a4d3a828a9c440f740d15",
            "1401e24ca220466b80a0e230b2de0d18",
            "176ae11ef37749008314891ff99ce4d2",
            "b44f2f4e096a43a191350d9df0afaebd",
            "a66497a2200b41618f0f818a476bb556",
            "18c65089faaa4d488c35f5f207f0f499",
            "8992fb182ac04c86a546b98a33cf27c1",
            "4154e7b81b4c48428e83e1441fe2f3c2",
            "9bfc5abf395c45458037929e837a77c5",
            "7070c25430e64c8e893f6cd68ada9185",
            "0e71e9a575d545dd82bd99a7a7ee3946",
            "24db1e04f7e5461f848e56261080e882",
            "bbb1d000b44a4624b39b31ec29bbe8fb",
            "b29eccae8663406a974e794a684e8981",
            "5855b890d7bd42dba37a78a41f73dc2e",
            "cb3547825b2c417f823524d6e83529a2",
            "bff0dc61cbd343318133e7d0de2c0f50",
            "a4cca4ca303843dd8dd8008ebb9d11aa"
          ]
        },
        "id": "9EfeEFKDGVEp",
        "outputId": "e87ea2ac-fc3c-4a2a-f82c-8ef16533d2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14fa7abfb7ba40a283d7ba9aedf0a4f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72181cc815fb42bfa619eb4ee6ca9b4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a31dd9e9ce1a4b5384507d0a0396a241",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60a7e62090fd445f9e3c7c9b6d060696",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea2476c889a84a28bda8d5cb807c8034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4154e7b81b4c48428e83e1441fe2f3c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3570' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3570/6000 12:44 < 08:40, 4.67 it/s, Epoch 1.78/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.008559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4320' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4320/6000 15:51 < 06:10, 4.54 it/s, Epoch 2.16/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.008559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.005839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_path = './trained_model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Function to get entities from text\n",
        "def get_entities(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512)\n",
        "    outputs = model(**inputs).logits\n",
        "    predictions = torch.argmax(outputs, dim=2)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    labels = [label_list[p] for p in predictions[0].numpy()]\n",
        "\n",
        "    entities = {\"CIVIL_NUMBER\": [], \"DATE_OF_BIRTH\": []}\n",
        "    current_entity = None\n",
        "    current_tokens = []\n",
        "\n",
        "    for token, label in zip(tokens, labels):\n",
        "        if label.startswith(\"B-\"):\n",
        "            if current_entity:\n",
        "                entities[current_entity].append(\" \".join(current_tokens))\n",
        "            current_entity = label.split(\"-\")[1]\n",
        "            current_tokens = [token]\n",
        "        elif label.startswith(\"I-\") and current_entity == label.split(\"-\")[1]:\n",
        "            current_tokens.append(token)\n",
        "        else:\n",
        "            if current_entity:\n",
        "                entities[current_entity].append(\" \".join(current_tokens))\n",
        "                current_entity = None\n",
        "            current_tokens = []\n",
        "\n",
        "    # Add last entity if exists\n",
        "    if current_entity:\n",
        "        entities[current_entity].append(\" \".join(current_tokens))\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "entities = get_entities(text)\n",
        "print(\"Extracted Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj9RwXlDQ8D0",
        "outputId": "6c152bd6-0019-4379-af9e-c237b9eb54f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Entities: {'CIVIL_NUMBER': ['##SA', '##E', '##Z', '##Z', 'nation', '##aut', '##y PA ##K ##IS ##TA ##NI - ID ##OM ##N ##7 ##33 ##0 ##38 ##48 < 0 < <'], 'DATE_OF_BIRTH': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJhBJM4iWd39",
        "outputId": "3ef4af14-7d3a-4819-f7bd-7535881986ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=33ae64b84a8a9366c6e762781bfc2fc22330a9961976fd477b79c7351a9a6244\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['tokens'],\n",
        "        truncation=True,\n",
        "        padding='max_length',  # Add padding\n",
        "        max_length=512,        # Define a maximum length\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label2id[label[word_idx]] if label[word_idx].startswith(\"I-\") else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs['labels'] = labels\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "EzsSK30jRWSJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('./resident_card_data_samples_with_junk.csv')\n",
        "\n",
        "# Ensure columns are treated as strings\n",
        "df['Sample Data'] = df['Sample Data'].astype(str)\n",
        "\n",
        "# Tokenize the 'Sample Data' column\n",
        "df['tokens'] = df['Sample Data'].apply(lambda x: x.split())\n",
        "\n",
        "# Create NER tags column with placeholder 'O' tags (Modify based on your tagging needs)\n",
        "df['ner_tags'] = df['tokens'].apply(lambda x: ['O'] * len(x))\n",
        "\n",
        "# Define label list and label mapping\n",
        "label_list = ['O', 'B-CIVIL_NUMBER', 'I-CIVIL_NUMBER', 'B-DATE_OF_BIRTH', 'I-DATE_OF_BIRTH']\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = 'bert-base-uncased'  # Replace with your pre-trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
        "\n",
        "# Tokenize and align labels\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['tokens'],\n",
        "        truncation=True,\n",
        "        padding='max_length',  # Add padding\n",
        "        max_length=512,        # Define a maximum length\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label2id[label[word_idx]] if label[word_idx].startswith(\"I-\") else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs['labels'] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True, remove_columns=['Sample Data', 'Date of Birth', 'Civil Number'])\n",
        "\n",
        "# Define compute metrics function\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = torch.tensor(predictions)  # Convert to tensor\n",
        "    predictions = torch.argmax(predictions, axis=2)\n",
        "\n",
        "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [[label_list[p] for p, l in zip(prediction, label) if l != -100]\n",
        "                        for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    results = classification_report(true_labels, true_predictions, output_dict=True)\n",
        "    return {\n",
        "        'precision': results['micro avg']['precision'],\n",
        "        'recall': results['micro avg']['recall'],\n",
        "        'f1': results['micro avg']['f1-score'],\n",
        "        'accuracy': results['accuracy'],\n",
        "    }\n",
        "\n",
        "\n",
        "# Split dataset into train and eval\n",
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "843973f29d4d4bfc9c5eb54bcd8abe79",
            "9e74e3f9a68141e2b0c422403d24f605",
            "40b3172ecb3040d092d4140d9f514d6a",
            "108098b06cd449bd8164170698665e18",
            "f6f6379f83ad4a1fa30fc13e80a89e39",
            "f08d5208149d4e7ebc97d2c3a07310c7",
            "30e728826b9d49bf9e771a3f95c1c38b",
            "b10b2c4713b54ddc825c240515e3baed",
            "a1aaff65c5f7456f9cd4d4591aa0e6bc",
            "e277ae80d8564c5c92d3806f4cde790b",
            "bffd6e613ec74c5593c4cca484645a54"
          ]
        },
        "id": "rv2EIHqVktMt",
        "outputId": "4d8a4b57-4c98-4e22-ae53-a6a8ece07837"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "843973f29d4d4bfc9c5eb54bcd8abe79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/3000 06:18 < 12:37, 2.64 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c51a1697a9e0>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2298\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2662\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2663\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3467\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3468\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3717\u001b[0m                 )\n\u001b[1;32m   3718\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3719\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3721\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-c51a1697a9e0>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = torch.tensor(predictions)  # Convert to tensor\n",
        "    predictions = torch.argmax(predictions, axis=2)\n",
        "\n",
        "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [[label_list[p] for p, l in zip(prediction, label) if l != -100]\n",
        "                        for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    results = classification_report(true_labels, true_predictions, output_dict=True)\n",
        "\n",
        "    # Default metrics to handle empty results\n",
        "    precision = results.get('micro avg', {}).get('precision', 0.0)\n",
        "    recall = results.get('micro avg', {}).get('recall', 0.0)\n",
        "    f1 = results.get('micro avg', {}).get('f1-score', 0.0)\n",
        "    accuracy = results.get('accuracy', 0.0)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'accuracy': accuracy,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "lhI79hkhnaa_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('./resident_card_data_full.csv')\n",
        "\n",
        "# Ensure columns are treated as strings\n",
        "df['Sample Data'] = df['Sample Data'].astype(str)\n",
        "\n",
        "# Tokenize the 'Sample Data' column\n",
        "df['tokens'] = df['Sample Data'].apply(lambda x: x.split())\n",
        "\n",
        "# Create NER tags column with placeholder 'O' tags (Modify based on your tagging needs)\n",
        "df['ner_tags'] = df['tokens'].apply(lambda x: ['O'] * len(x))\n",
        "\n",
        "# Define label list and label mapping\n",
        "label_list = ['O', 'B-CIVIL_NUMBER', 'I-CIVIL_NUMBER', 'B-DATE_OF_BIRTH', 'I-DATE_OF_BIRTH']\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = 'bert-base-uncased'  # Replace with your pre-trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
        "\n",
        "# Tokenize and align labels\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['tokens'],\n",
        "        truncation=True,\n",
        "        padding='max_length',  # Add padding\n",
        "        max_length=512,        # Define a maximum length\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label2id[label[word_idx]] if label[word_idx].startswith(\"I-\") else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs['labels'] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True, remove_columns=['Sample Data', 'Date of Birth', 'Civil Number'])\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = torch.tensor(predictions)  # Convert to tensor\n",
        "    predictions = torch.argmax(predictions, axis=2)\n",
        "\n",
        "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [[label_list[p] for p, l in zip(prediction, label) if l != -100]\n",
        "                        for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    results = classification_report(true_labels, true_predictions, output_dict=True)\n",
        "\n",
        "    # Default metrics to handle empty results\n",
        "    precision = results.get('micro avg', {}).get('precision', 0.0)\n",
        "    recall = results.get('micro avg', {}).get('recall', 0.0)\n",
        "    f1 = results.get('micro avg', {}).get('f1-score', 0.0)\n",
        "    accuracy = results.get('accuracy', 0.0)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'accuracy': accuracy,\n",
        "    }\n",
        "\n",
        "# Split dataset into train and eval\n",
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877,
          "referenced_widgets": [
            "0edde7206535445d9589c72255846b77",
            "fccca33abf2e4e15a2b12c613343e523",
            "73f392e8a3594598af7f996750d218d5",
            "893733fa7b064799af79c7510ff8e334",
            "fce9f6932ddf42998ad7cad6bf5cc606",
            "2970c4e4ce204d2caaa5c4b21257f765",
            "cce02c855c994afb890a1a57b46c42bc",
            "6ad4a428b5f04f1c8b8081d3a736665e",
            "5dc12de6efb6445fa12eec34e700f297",
            "6270e47347194675ab51e77181e70aa5",
            "2071cf91c8154f1f92613ee83ab72cf3"
          ]
        },
        "id": "xQl31sBspmKi",
        "outputId": "6f0234c1-32df-4c7a-f05e-91c22695858e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0edde7206535445d9589c72255846b77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2762' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2762/3000 18:55 < 01:37, 2.43 it/s, Epoch 2.76/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-ffc2d530451a>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2209\u001b[0m                 ):\n\u001b[1;32m   2210\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = './trained_model'  # Path to your fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example text for inference\n",
        "example_text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize and get predictions\n",
        "tokens = tokenizer(example_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "outputs = model(**tokens)\n",
        "\n",
        "# Get predictions\n",
        "predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Decode predictions\n",
        "label_list = model.config.id2label\n",
        "predicted_labels = [label_list[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "# Display results\n",
        "print(\"Token\\t\\tPrediction\")\n",
        "for token, label in zip(tokens['input_ids'][0], predicted_labels):\n",
        "    print(f\"{tokenizer.decode([token])}\\t\\t{label}\")\n",
        "\n",
        "# Alternatively, using the pipeline directly\n",
        "result = nlp(example_text)\n",
        "for entity in result:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67vAnhnZvgmZ",
        "outputId": "46a28bd0-5bde-4705-ab5c-b70c22f4c734"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tPrediction\n",
            "[CLS]\t\tLABEL_0\n",
            "8\t\tLABEL_0\n",
            "?\t\tLABEL_0\n",
            "fit\t\tLABEL_0\n",
            "ft\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##ke\t\tLABEL_0\n",
            "\\\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "##LT\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##N\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##ES\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##T\t\tLABEL_0\n",
            "CA\t\tLABEL_0\n",
            "##RD\t\tLABEL_0\n",
            "88\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##00\t\tLABEL_0\n",
            "##1\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##31\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##3\t\tLABEL_0\n",
            "124\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##8\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "N\t\tLABEL_0\n",
            "##UM\t\tLABEL_0\n",
            "##BE\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##ye\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "Kyle\t\tLABEL_0\n",
            ":\t\tLABEL_0\n",
            "73\t\tLABEL_0\n",
            "##30\t\tLABEL_0\n",
            "##38\t\tLABEL_0\n",
            "##48\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##lla\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##X\t\tLABEL_0\n",
            "##PI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "06\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "2004\t\tLABEL_0\n",
            "Ha\t\tLABEL_0\n",
            "##w\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##at\t\tLABEL_0\n",
            "sign\t\tLABEL_0\n",
            "##av\t\tLABEL_0\n",
            "##une\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##x\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "-\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##F\t\tLABEL_0\n",
            "B\t\tLABEL_0\n",
            "##IR\t\tLABEL_0\n",
            "##TH\t\tLABEL_0\n",
            "01\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "1982\t\tLABEL_0\n",
            "shy\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "'\t\tLABEL_0\n",
            "~\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "“\t\tLABEL_0\n",
            "A\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "he\t\tLABEL_0\n",
            "##n\t\tLABEL_0\n",
            "SL\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##IS\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##no\t\tLABEL_0\n",
            "s\t\tLABEL_0\n",
            "##har\t\tLABEL_0\n",
            "ka\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "ya\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##sh\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "op\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##i\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "steel\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##y\t\tLABEL_0\n",
            "a\t\tLABEL_0\n",
            "eagle\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##pit\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##ya\t\tLABEL_0\n",
            "at\t\tLABEL_0\n",
            "V\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "##H\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "OR\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##NG\t\tLABEL_0\n",
            "L\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##CE\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##O\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            "##AL\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "P\t\tLABEL_0\n",
            "##OL\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##LA\t\tLABEL_0\n",
            "##SS\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "ST\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "NO\t\tLABEL_0\n",
            "##TE\t\tLABEL_0\n",
            "Z\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "##TS\t\tLABEL_0\n",
            "##S\t\tLABEL_0\n",
            "Name\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_1\n",
            "##IN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##BI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "j\t\tLABEL_0\n",
            "##a\t\tLABEL_0\n",
            "Pen\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "t\t\tLABEL_0\n",
            "##tt\t\tLABEL_0\n",
            "SS\t\tLABEL_0\n",
            "##A\t\tLABEL_0\n",
            "##E\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "”\t\tLABEL_0\n",
            "nation\t\tLABEL_1\n",
            "##aut\t\tLABEL_1\n",
            "##y\t\tLABEL_1\n",
            "PA\t\tLABEL_2\n",
            "##K\t\tLABEL_2\n",
            "##IS\t\tLABEL_2\n",
            "##TA\t\tLABEL_2\n",
            "##NI\t\tLABEL_2\n",
            "-\t\tLABEL_2\n",
            "ID\t\tLABEL_2\n",
            "##OM\t\tLABEL_2\n",
            "##N\t\tLABEL_2\n",
            "##7\t\tLABEL_2\n",
            "##33\t\tLABEL_2\n",
            "##0\t\tLABEL_2\n",
            "##38\t\tLABEL_2\n",
            "##48\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "0\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "c\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##cs\t\tLABEL_0\n",
            "##ee\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "82\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##51\t\tLABEL_0\n",
            "##22\t\tLABEL_0\n",
            "##M\t\tLABEL_0\n",
            "##24\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##50\t\tLABEL_0\n",
            "##6\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##PA\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "##2\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "ID\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_0\n",
            "##IN\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "[SEP]\t\tLABEL_0\n",
            "Entity: 8? fit ft eke \\ SULTANATE OF OMAN RESIDENT CARD 88C001C3103 12478 CIVIL NUMBER oye ee Kyle : 73303848 olla oe EE EXPIRY. DATE 06 / 05 / 2004 Haw gat signavune yx DATE - GF BIRTH 01 / 05 / 1982 shyt ' ~. “ Ae hen SLU GIS HE Sno shar kat OI yal Yl Osh OU ope gi gl steel yy a eagle Spite Oya at VEHICLE ORIVING LICENCE ROYAL OMAR POLICE CLASS D. C. OF CLVIL STATUS NOTE ZLETSS Name IMRAN SAJID HUS, Label: LABEL_0\n",
            "Entity: ##SA, Label: LABEL_1\n",
            "Entity: ##IN SABIR ja Pen Y ttt SSA, Label: LABEL_0\n",
            "Entity: ##EZZ, Label: LABEL_1\n",
            "Entity: ”, Label: LABEL_0\n",
            "Entity: nationauty, Label: LABEL_1\n",
            "Entity: PAKISTANI - IDOMN73303848 < 0 < <, Label: LABEL_2\n",
            "Entity: < < < < K < cKcccsee < 8205122M2405067PAK < < < < < < < < Kccc2 IMRAN < SAJ ID < HUSSAINK < < < < < < < ccc <, Label: LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = './trained_model'  # Path to your fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example text for inference\n",
        "example_text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize and get predictions\n",
        "tokens = tokenizer(example_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "outputs = model(**tokens)\n",
        "\n",
        "# Get predictions\n",
        "predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Decode predictions\n",
        "label_list = model.config.id2label\n",
        "predicted_labels = [label_list[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "# Display results\n",
        "print(\"Token\\t\\tPrediction\")\n",
        "for token, label in zip(tokens['input_ids'][0], predicted_labels):\n",
        "    print(f\"{tokenizer.decode([token])}\\t\\t{label}\")\n",
        "\n",
        "# Alternatively, using the pipeline directly\n",
        "result = nlp(example_text)\n",
        "for entity in result:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA8ozXlXwMOR",
        "outputId": "0803f0a1-5f57-4937-8799-dc818b42bbf5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tPrediction\n",
            "[CLS]\t\tLABEL_0\n",
            "8\t\tLABEL_0\n",
            "?\t\tLABEL_0\n",
            "fit\t\tLABEL_0\n",
            "ft\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##ke\t\tLABEL_0\n",
            "\\\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "##LT\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##N\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##ES\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##T\t\tLABEL_0\n",
            "CA\t\tLABEL_0\n",
            "##RD\t\tLABEL_0\n",
            "88\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##00\t\tLABEL_0\n",
            "##1\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##31\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##3\t\tLABEL_0\n",
            "124\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##8\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "N\t\tLABEL_0\n",
            "##UM\t\tLABEL_0\n",
            "##BE\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##ye\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "Kyle\t\tLABEL_0\n",
            ":\t\tLABEL_0\n",
            "73\t\tLABEL_0\n",
            "##30\t\tLABEL_0\n",
            "##38\t\tLABEL_0\n",
            "##48\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##lla\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##X\t\tLABEL_0\n",
            "##PI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "06\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "2004\t\tLABEL_0\n",
            "Ha\t\tLABEL_0\n",
            "##w\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##at\t\tLABEL_0\n",
            "sign\t\tLABEL_0\n",
            "##av\t\tLABEL_0\n",
            "##une\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##x\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "-\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##F\t\tLABEL_0\n",
            "B\t\tLABEL_0\n",
            "##IR\t\tLABEL_0\n",
            "##TH\t\tLABEL_0\n",
            "01\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "1982\t\tLABEL_0\n",
            "shy\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "'\t\tLABEL_0\n",
            "~\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "“\t\tLABEL_0\n",
            "A\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "he\t\tLABEL_0\n",
            "##n\t\tLABEL_0\n",
            "SL\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##IS\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##no\t\tLABEL_0\n",
            "s\t\tLABEL_0\n",
            "##har\t\tLABEL_0\n",
            "ka\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "ya\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##sh\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "op\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##i\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "steel\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##y\t\tLABEL_0\n",
            "a\t\tLABEL_0\n",
            "eagle\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##pit\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##ya\t\tLABEL_0\n",
            "at\t\tLABEL_0\n",
            "V\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "##H\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "OR\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##NG\t\tLABEL_0\n",
            "L\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##CE\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##O\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            "##AL\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "P\t\tLABEL_0\n",
            "##OL\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##LA\t\tLABEL_0\n",
            "##SS\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "ST\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "NO\t\tLABEL_0\n",
            "##TE\t\tLABEL_0\n",
            "Z\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "##TS\t\tLABEL_0\n",
            "##S\t\tLABEL_0\n",
            "Name\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_1\n",
            "##IN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##BI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "j\t\tLABEL_0\n",
            "##a\t\tLABEL_0\n",
            "Pen\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "t\t\tLABEL_0\n",
            "##tt\t\tLABEL_0\n",
            "SS\t\tLABEL_0\n",
            "##A\t\tLABEL_0\n",
            "##E\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "”\t\tLABEL_0\n",
            "nation\t\tLABEL_1\n",
            "##aut\t\tLABEL_1\n",
            "##y\t\tLABEL_1\n",
            "PA\t\tLABEL_2\n",
            "##K\t\tLABEL_2\n",
            "##IS\t\tLABEL_2\n",
            "##TA\t\tLABEL_2\n",
            "##NI\t\tLABEL_2\n",
            "-\t\tLABEL_2\n",
            "ID\t\tLABEL_2\n",
            "##OM\t\tLABEL_2\n",
            "##N\t\tLABEL_2\n",
            "##7\t\tLABEL_2\n",
            "##33\t\tLABEL_2\n",
            "##0\t\tLABEL_2\n",
            "##38\t\tLABEL_2\n",
            "##48\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "0\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "c\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##cs\t\tLABEL_0\n",
            "##ee\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "82\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##51\t\tLABEL_0\n",
            "##22\t\tLABEL_0\n",
            "##M\t\tLABEL_0\n",
            "##24\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##50\t\tLABEL_0\n",
            "##6\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##PA\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "##2\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "ID\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_0\n",
            "##IN\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "[SEP]\t\tLABEL_0\n",
            "Entity: 8? fit ft eke \\ SULTANATE OF OMAN RESIDENT CARD 88C001C3103 12478 CIVIL NUMBER oye ee Kyle : 73303848 olla oe EE EXPIRY. DATE 06 / 05 / 2004 Haw gat signavune yx DATE - GF BIRTH 01 / 05 / 1982 shyt ' ~. “ Ae hen SLU GIS HE Sno shar kat OI yal Yl Osh OU ope gi gl steel yy a eagle Spite Oya at VEHICLE ORIVING LICENCE ROYAL OMAR POLICE CLASS D. C. OF CLVIL STATUS NOTE ZLETSS Name IMRAN SAJID HUS, Label: LABEL_0\n",
            "Entity: ##SA, Label: LABEL_1\n",
            "Entity: ##IN SABIR ja Pen Y ttt SSA, Label: LABEL_0\n",
            "Entity: ##EZZ, Label: LABEL_1\n",
            "Entity: ”, Label: LABEL_0\n",
            "Entity: nationauty, Label: LABEL_1\n",
            "Entity: PAKISTANI - IDOMN73303848 < 0 < <, Label: LABEL_2\n",
            "Entity: < < < < K < cKcccsee < 8205122M2405067PAK < < < < < < < < Kccc2 IMRAN < SAJ ID < HUSSAINK < < < < < < < ccc <, Label: LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "#model_path = './results'  # Update this with your model path\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example text for inference\n",
        "example_text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer(example_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Convert predictions to labels\n",
        "label_list = model.config.id2label\n",
        "predicted_labels = [label_list[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "# Display the tokens and their predicted labels\n",
        "print(\"Token\\t\\tPrediction\")\n",
        "for token, label in zip(tokens['input_ids'][0], predicted_labels):\n",
        "    print(f\"{tokenizer.decode([token]).strip()}\\t\\t{label}\")\n",
        "\n",
        "# Alternatively, use the pipeline for entity extraction\n",
        "result = nlp(example_text)\n",
        "print(\"\\nExtracted Entities:\")\n",
        "for entity in result:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_xcvQP4wp09",
        "outputId": "77b3c7bb-ce85-4984-b105-3e5c462cf6b0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tPrediction\n",
            "[CLS]\t\tLABEL_0\n",
            "8\t\tLABEL_0\n",
            "?\t\tLABEL_0\n",
            "fit\t\tLABEL_0\n",
            "ft\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##ke\t\tLABEL_0\n",
            "\\\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "##LT\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##N\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##ES\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##T\t\tLABEL_0\n",
            "CA\t\tLABEL_0\n",
            "##RD\t\tLABEL_0\n",
            "88\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##00\t\tLABEL_0\n",
            "##1\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##31\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##3\t\tLABEL_0\n",
            "124\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##8\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "N\t\tLABEL_0\n",
            "##UM\t\tLABEL_0\n",
            "##BE\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##ye\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "Kyle\t\tLABEL_0\n",
            ":\t\tLABEL_0\n",
            "73\t\tLABEL_0\n",
            "##30\t\tLABEL_0\n",
            "##38\t\tLABEL_0\n",
            "##48\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##lla\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##X\t\tLABEL_0\n",
            "##PI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "06\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "2004\t\tLABEL_0\n",
            "Ha\t\tLABEL_0\n",
            "##w\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##at\t\tLABEL_0\n",
            "sign\t\tLABEL_0\n",
            "##av\t\tLABEL_0\n",
            "##une\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##x\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "-\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##F\t\tLABEL_0\n",
            "B\t\tLABEL_0\n",
            "##IR\t\tLABEL_0\n",
            "##TH\t\tLABEL_0\n",
            "01\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "1982\t\tLABEL_0\n",
            "shy\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "'\t\tLABEL_0\n",
            "~\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "“\t\tLABEL_0\n",
            "A\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "he\t\tLABEL_0\n",
            "##n\t\tLABEL_0\n",
            "SL\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##IS\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##no\t\tLABEL_0\n",
            "s\t\tLABEL_0\n",
            "##har\t\tLABEL_0\n",
            "ka\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "ya\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##sh\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "op\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##i\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "steel\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##y\t\tLABEL_0\n",
            "a\t\tLABEL_0\n",
            "eagle\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##pit\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##ya\t\tLABEL_0\n",
            "at\t\tLABEL_0\n",
            "V\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "##H\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "OR\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##NG\t\tLABEL_0\n",
            "L\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##CE\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##O\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            "##AL\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "P\t\tLABEL_0\n",
            "##OL\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##LA\t\tLABEL_0\n",
            "##SS\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "ST\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "NO\t\tLABEL_0\n",
            "##TE\t\tLABEL_0\n",
            "Z\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "##TS\t\tLABEL_0\n",
            "##S\t\tLABEL_0\n",
            "Name\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_1\n",
            "##IN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##BI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "j\t\tLABEL_0\n",
            "##a\t\tLABEL_0\n",
            "Pen\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "t\t\tLABEL_0\n",
            "##tt\t\tLABEL_0\n",
            "SS\t\tLABEL_0\n",
            "##A\t\tLABEL_0\n",
            "##E\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "”\t\tLABEL_0\n",
            "nation\t\tLABEL_1\n",
            "##aut\t\tLABEL_1\n",
            "##y\t\tLABEL_1\n",
            "PA\t\tLABEL_2\n",
            "##K\t\tLABEL_2\n",
            "##IS\t\tLABEL_2\n",
            "##TA\t\tLABEL_2\n",
            "##NI\t\tLABEL_2\n",
            "-\t\tLABEL_2\n",
            "ID\t\tLABEL_2\n",
            "##OM\t\tLABEL_2\n",
            "##N\t\tLABEL_2\n",
            "##7\t\tLABEL_2\n",
            "##33\t\tLABEL_2\n",
            "##0\t\tLABEL_2\n",
            "##38\t\tLABEL_2\n",
            "##48\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "0\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "c\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##cs\t\tLABEL_0\n",
            "##ee\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "82\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##51\t\tLABEL_0\n",
            "##22\t\tLABEL_0\n",
            "##M\t\tLABEL_0\n",
            "##24\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##50\t\tLABEL_0\n",
            "##6\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##PA\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "##2\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "ID\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_0\n",
            "##IN\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "[SEP]\t\tLABEL_0\n",
            "\n",
            "Extracted Entities:\n",
            "Entity: 8? fit ft eke \\ SULTANATE OF OMAN RESIDENT CARD 88C001C3103 12478 CIVIL NUMBER oye ee Kyle : 73303848 olla oe EE EXPIRY. DATE 06 / 05 / 2004 Haw gat signavune yx DATE - GF BIRTH 01 / 05 / 1982 shyt ' ~. “ Ae hen SLU GIS HE Sno shar kat OI yal Yl Osh OU ope gi gl steel yy a eagle Spite Oya at VEHICLE ORIVING LICENCE ROYAL OMAR POLICE CLASS D. C. OF CLVIL STATUS NOTE ZLETSS Name IMRAN SAJID HUS, Label: LABEL_0\n",
            "Entity: ##SA, Label: LABEL_1\n",
            "Entity: ##IN SABIR ja Pen Y ttt SSA, Label: LABEL_0\n",
            "Entity: ##EZZ, Label: LABEL_1\n",
            "Entity: ”, Label: LABEL_0\n",
            "Entity: nationauty, Label: LABEL_1\n",
            "Entity: PAKISTANI - IDOMN73303848 < 0 < <, Label: LABEL_2\n",
            "Entity: < < < < K < cKcccsee < 8205122M2405067PAK < < < < < < < < Kccc2 IMRAN < SAJ ID < HUSSAINK < < < < < < < ccc <, Label: LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "#model_path = './results'  # Update this with your model path\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example text for inference\n",
        "example_text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer(example_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Convert predictions to labels\n",
        "label_list = model.config.id2label\n",
        "predicted_labels = [label_list[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "# Display the tokens and their predicted labels\n",
        "print(\"Token\\t\\tPrediction\")\n",
        "for token, label in zip(tokens['input_ids'][0], predicted_labels):\n",
        "    print(f\"{tokenizer.decode([token]).strip()}\\t\\t{label}\")\n",
        "\n",
        "# Alternatively, use the pipeline for entity extraction\n",
        "result = nlp(example_text)\n",
        "print(\"\\nExtracted Entities:\")\n",
        "for entity in result:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpaAR2gnxEw5",
        "outputId": "184d9980-ae51-4a62-f183-70daf1b43aec"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tPrediction\n",
            "[CLS]\t\tLABEL_0\n",
            "8\t\tLABEL_0\n",
            "?\t\tLABEL_0\n",
            "fit\t\tLABEL_0\n",
            "ft\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##ke\t\tLABEL_0\n",
            "\\\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "##LT\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##N\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##ES\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##T\t\tLABEL_0\n",
            "CA\t\tLABEL_0\n",
            "##RD\t\tLABEL_0\n",
            "88\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##00\t\tLABEL_0\n",
            "##1\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##31\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##3\t\tLABEL_0\n",
            "124\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##8\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "N\t\tLABEL_0\n",
            "##UM\t\tLABEL_0\n",
            "##BE\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##ye\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "Kyle\t\tLABEL_0\n",
            ":\t\tLABEL_0\n",
            "73\t\tLABEL_0\n",
            "##30\t\tLABEL_0\n",
            "##38\t\tLABEL_0\n",
            "##48\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##lla\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##X\t\tLABEL_0\n",
            "##PI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "06\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "2004\t\tLABEL_0\n",
            "Ha\t\tLABEL_0\n",
            "##w\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##at\t\tLABEL_0\n",
            "sign\t\tLABEL_0\n",
            "##av\t\tLABEL_0\n",
            "##une\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##x\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "-\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##F\t\tLABEL_0\n",
            "B\t\tLABEL_0\n",
            "##IR\t\tLABEL_0\n",
            "##TH\t\tLABEL_0\n",
            "01\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "1982\t\tLABEL_0\n",
            "shy\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "'\t\tLABEL_0\n",
            "~\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "“\t\tLABEL_0\n",
            "A\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "he\t\tLABEL_0\n",
            "##n\t\tLABEL_0\n",
            "SL\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##IS\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##no\t\tLABEL_0\n",
            "s\t\tLABEL_0\n",
            "##har\t\tLABEL_0\n",
            "ka\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "ya\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##sh\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "op\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##i\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "steel\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##y\t\tLABEL_0\n",
            "a\t\tLABEL_0\n",
            "eagle\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##pit\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##ya\t\tLABEL_0\n",
            "at\t\tLABEL_0\n",
            "V\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "##H\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "OR\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##NG\t\tLABEL_0\n",
            "L\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##CE\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##O\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            "##AL\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "P\t\tLABEL_0\n",
            "##OL\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##LA\t\tLABEL_0\n",
            "##SS\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "ST\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "NO\t\tLABEL_0\n",
            "##TE\t\tLABEL_0\n",
            "Z\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "##TS\t\tLABEL_0\n",
            "##S\t\tLABEL_0\n",
            "Name\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_1\n",
            "##IN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##BI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "j\t\tLABEL_0\n",
            "##a\t\tLABEL_0\n",
            "Pen\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "t\t\tLABEL_0\n",
            "##tt\t\tLABEL_0\n",
            "SS\t\tLABEL_0\n",
            "##A\t\tLABEL_0\n",
            "##E\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "”\t\tLABEL_0\n",
            "nation\t\tLABEL_1\n",
            "##aut\t\tLABEL_1\n",
            "##y\t\tLABEL_1\n",
            "PA\t\tLABEL_2\n",
            "##K\t\tLABEL_2\n",
            "##IS\t\tLABEL_2\n",
            "##TA\t\tLABEL_2\n",
            "##NI\t\tLABEL_2\n",
            "-\t\tLABEL_2\n",
            "ID\t\tLABEL_2\n",
            "##OM\t\tLABEL_2\n",
            "##N\t\tLABEL_2\n",
            "##7\t\tLABEL_2\n",
            "##33\t\tLABEL_2\n",
            "##0\t\tLABEL_2\n",
            "##38\t\tLABEL_2\n",
            "##48\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "0\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "c\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##cs\t\tLABEL_0\n",
            "##ee\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "82\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##51\t\tLABEL_0\n",
            "##22\t\tLABEL_0\n",
            "##M\t\tLABEL_0\n",
            "##24\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##50\t\tLABEL_0\n",
            "##6\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##PA\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "##2\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "ID\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_0\n",
            "##IN\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "[SEP]\t\tLABEL_0\n",
            "\n",
            "Extracted Entities:\n",
            "Entity: 8? fit ft eke \\ SULTANATE OF OMAN RESIDENT CARD 88C001C3103 12478 CIVIL NUMBER oye ee Kyle : 73303848 olla oe EE EXPIRY. DATE 06 / 05 / 2004 Haw gat signavune yx DATE - GF BIRTH 01 / 05 / 1982 shyt ' ~. “ Ae hen SLU GIS HE Sno shar kat OI yal Yl Osh OU ope gi gl steel yy a eagle Spite Oya at VEHICLE ORIVING LICENCE ROYAL OMAR POLICE CLASS D. C. OF CLVIL STATUS NOTE ZLETSS Name IMRAN SAJID HUS, Label: LABEL_0\n",
            "Entity: ##SA, Label: LABEL_1\n",
            "Entity: ##IN SABIR ja Pen Y ttt SSA, Label: LABEL_0\n",
            "Entity: ##EZZ, Label: LABEL_1\n",
            "Entity: ”, Label: LABEL_0\n",
            "Entity: nationauty, Label: LABEL_1\n",
            "Entity: PAKISTANI - IDOMN73303848 < 0 < <, Label: LABEL_2\n",
            "Entity: < < < < K < cKcccsee < 8205122M2405067PAK < < < < < < < < Kccc2 IMRAN < SAJ ID < HUSSAINK < < < < < < < ccc <, Label: LABEL_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = './trained_model'  # Update this with your model path\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example text for inference\n",
        "example_text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE-GF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(example_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Convert predictions to labels\n",
        "label_list = model.config.id2label\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "predicted_labels = [label_list[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "# Function to merge tokens\n",
        "def merge_tokens(tokens, labels):\n",
        "    words, merged_labels = [], []\n",
        "    current_word, current_label = '', ''\n",
        "\n",
        "    for token, label in zip(tokens, labels):\n",
        "        if token.startswith('##'):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            if current_word:\n",
        "                words.append(current_word)\n",
        "                merged_labels.append(current_label)\n",
        "            current_word = token\n",
        "            current_label = label\n",
        "\n",
        "    if current_word:  # Append the last token\n",
        "        words.append(current_word)\n",
        "        merged_labels.append(current_label)\n",
        "\n",
        "    return words, merged_labels\n",
        "\n",
        "# Merge tokens and labels\n",
        "words, labels = merge_tokens(tokens, predicted_labels)\n",
        "\n",
        "# Display the tokens and their predicted labels\n",
        "print(\"Token\\t\\tPrediction\")\n",
        "for token, label in zip(tokens, predicted_labels):\n",
        "    if token not in tokenizer.all_special_tokens:\n",
        "        print(f\"{token}\\t\\t{label}\")\n",
        "\n",
        "# Display the merged entities\n",
        "print(\"\\nMerged Entities:\")\n",
        "for word, label in zip(words, labels):\n",
        "    print(f\"Word: {word}, Label: {label}\")\n",
        "\n",
        "# Extract entities using the pipeline\n",
        "result = nlp(example_text)\n",
        "print(\"\\nExtracted Entities:\")\n",
        "for entity in result:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}\")\n",
        "\n",
        "# Extract specific entities\n",
        "civil_number = []\n",
        "date_of_birth = []\n",
        "\n",
        "for word, label in zip(words, labels):\n",
        "    if 'CIVIL_NUMBER' in label:\n",
        "        civil_number.append(word)\n",
        "    elif 'DATE_OF_BIRTH' in label:\n",
        "        date_of_birth.append(word)\n",
        "\n",
        "# Print extracted CIVIL_NUMBER and DATE_OF_BIRTH\n",
        "print(\"\\nExtracted CIVIL_NUMBER:\")\n",
        "print(\" \".join(civil_number))\n",
        "\n",
        "print(\"\\nExtracted DATE_OF_BIRTH:\")\n",
        "print(\" \".join(date_of_birth))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8Yw0TVCzVOt",
        "outputId": "ee40dff1-5918-4437-eab7-e977a62c532a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tPrediction\n",
            "8\t\tLABEL_0\n",
            "?\t\tLABEL_0\n",
            "fit\t\tLABEL_0\n",
            "ft\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##ke\t\tLABEL_0\n",
            "\\\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "##LT\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##N\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##ES\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##T\t\tLABEL_0\n",
            "CA\t\tLABEL_0\n",
            "##RD\t\tLABEL_0\n",
            "88\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##00\t\tLABEL_0\n",
            "##1\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##31\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##3\t\tLABEL_0\n",
            "124\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##8\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "N\t\tLABEL_0\n",
            "##UM\t\tLABEL_0\n",
            "##BE\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##ye\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "Kyle\t\tLABEL_0\n",
            ":\t\tLABEL_0\n",
            "73\t\tLABEL_0\n",
            "##30\t\tLABEL_0\n",
            "##38\t\tLABEL_0\n",
            "##48\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##lla\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##X\t\tLABEL_0\n",
            "##PI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "06\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "2004\t\tLABEL_0\n",
            "Ha\t\tLABEL_0\n",
            "##w\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##at\t\tLABEL_0\n",
            "sign\t\tLABEL_0\n",
            "##av\t\tLABEL_0\n",
            "##une\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##x\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "-\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##F\t\tLABEL_0\n",
            "B\t\tLABEL_0\n",
            "##IR\t\tLABEL_0\n",
            "##TH\t\tLABEL_0\n",
            "01\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "1982\t\tLABEL_0\n",
            "shy\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "'\t\tLABEL_0\n",
            "~\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "“\t\tLABEL_0\n",
            "A\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "he\t\tLABEL_0\n",
            "##n\t\tLABEL_0\n",
            "SL\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##IS\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##no\t\tLABEL_0\n",
            "s\t\tLABEL_0\n",
            "##har\t\tLABEL_0\n",
            "ka\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "ya\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##sh\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "op\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##i\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "steel\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##y\t\tLABEL_0\n",
            "a\t\tLABEL_0\n",
            "eagle\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##pit\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##ya\t\tLABEL_0\n",
            "at\t\tLABEL_0\n",
            "V\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "##H\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "OR\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##NG\t\tLABEL_0\n",
            "L\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##CE\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##O\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            "##AL\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "P\t\tLABEL_0\n",
            "##OL\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##LA\t\tLABEL_0\n",
            "##SS\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "ST\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "NO\t\tLABEL_0\n",
            "##TE\t\tLABEL_0\n",
            "Z\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "##TS\t\tLABEL_0\n",
            "##S\t\tLABEL_0\n",
            "Name\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_1\n",
            "##IN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##BI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "j\t\tLABEL_0\n",
            "##a\t\tLABEL_0\n",
            "Pen\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "t\t\tLABEL_0\n",
            "##tt\t\tLABEL_0\n",
            "SS\t\tLABEL_0\n",
            "##A\t\tLABEL_0\n",
            "##E\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "”\t\tLABEL_0\n",
            "nation\t\tLABEL_1\n",
            "##aut\t\tLABEL_1\n",
            "##y\t\tLABEL_1\n",
            "PA\t\tLABEL_2\n",
            "##K\t\tLABEL_2\n",
            "##IS\t\tLABEL_2\n",
            "##TA\t\tLABEL_2\n",
            "##NI\t\tLABEL_2\n",
            "-\t\tLABEL_2\n",
            "ID\t\tLABEL_2\n",
            "##OM\t\tLABEL_2\n",
            "##N\t\tLABEL_2\n",
            "##7\t\tLABEL_2\n",
            "##33\t\tLABEL_2\n",
            "##0\t\tLABEL_2\n",
            "##38\t\tLABEL_2\n",
            "##48\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "0\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "c\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##cs\t\tLABEL_0\n",
            "##ee\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "82\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##51\t\tLABEL_0\n",
            "##22\t\tLABEL_0\n",
            "##M\t\tLABEL_0\n",
            "##24\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##50\t\tLABEL_0\n",
            "##6\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##PA\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "##2\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "ID\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_0\n",
            "##IN\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "\n",
            "Merged Entities:\n",
            "Word: [CLS], Label: LABEL_0\n",
            "Word: 8, Label: LABEL_0\n",
            "Word: ?, Label: LABEL_0\n",
            "Word: fit, Label: LABEL_0\n",
            "Word: ft, Label: LABEL_0\n",
            "Word: eke, Label: LABEL_0\n",
            "Word: \\, Label: LABEL_0\n",
            "Word: SULTANATE, Label: LABEL_0\n",
            "Word: OF, Label: LABEL_0\n",
            "Word: OMAN, Label: LABEL_0\n",
            "Word: RESIDENT, Label: LABEL_0\n",
            "Word: CARD, Label: LABEL_0\n",
            "Word: 88C001C3103, Label: LABEL_0\n",
            "Word: 12478, Label: LABEL_0\n",
            "Word: CIVIL, Label: LABEL_0\n",
            "Word: NUMBER, Label: LABEL_0\n",
            "Word: oye, Label: LABEL_0\n",
            "Word: ee, Label: LABEL_0\n",
            "Word: Kyle, Label: LABEL_0\n",
            "Word: :, Label: LABEL_0\n",
            "Word: 73303848, Label: LABEL_0\n",
            "Word: olla, Label: LABEL_0\n",
            "Word: oe, Label: LABEL_0\n",
            "Word: EE, Label: LABEL_0\n",
            "Word: EXPIRY, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: DATE, Label: LABEL_0\n",
            "Word: 06, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 05, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 2004, Label: LABEL_0\n",
            "Word: Haw, Label: LABEL_0\n",
            "Word: gat, Label: LABEL_0\n",
            "Word: signavune, Label: LABEL_0\n",
            "Word: yx, Label: LABEL_0\n",
            "Word: DATE, Label: LABEL_0\n",
            "Word: -, Label: LABEL_0\n",
            "Word: GF, Label: LABEL_0\n",
            "Word: BIRTH, Label: LABEL_0\n",
            "Word: 01, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 05, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 1982, Label: LABEL_0\n",
            "Word: shyt, Label: LABEL_0\n",
            "Word: ', Label: LABEL_0\n",
            "Word: ~, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: “, Label: LABEL_0\n",
            "Word: Ae, Label: LABEL_0\n",
            "Word: hen, Label: LABEL_0\n",
            "Word: SLU, Label: LABEL_0\n",
            "Word: GIS, Label: LABEL_0\n",
            "Word: HE, Label: LABEL_0\n",
            "Word: Sno, Label: LABEL_0\n",
            "Word: shar, Label: LABEL_0\n",
            "Word: kat, Label: LABEL_0\n",
            "Word: OI, Label: LABEL_0\n",
            "Word: yal, Label: LABEL_0\n",
            "Word: Yl, Label: LABEL_0\n",
            "Word: Osh, Label: LABEL_0\n",
            "Word: OU, Label: LABEL_0\n",
            "Word: ope, Label: LABEL_0\n",
            "Word: gi, Label: LABEL_0\n",
            "Word: gl, Label: LABEL_0\n",
            "Word: steel, Label: LABEL_0\n",
            "Word: yy, Label: LABEL_0\n",
            "Word: a, Label: LABEL_0\n",
            "Word: eagle, Label: LABEL_0\n",
            "Word: Spite, Label: LABEL_0\n",
            "Word: Oya, Label: LABEL_0\n",
            "Word: at, Label: LABEL_0\n",
            "Word: VEHICLE, Label: LABEL_0\n",
            "Word: ORIVING, Label: LABEL_0\n",
            "Word: LICENCE, Label: LABEL_0\n",
            "Word: ROYAL, Label: LABEL_0\n",
            "Word: OMAR, Label: LABEL_0\n",
            "Word: POLICE, Label: LABEL_0\n",
            "Word: CLASS, Label: LABEL_0\n",
            "Word: D, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: C, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: OF, Label: LABEL_0\n",
            "Word: CLVIL, Label: LABEL_0\n",
            "Word: STATUS, Label: LABEL_0\n",
            "Word: NOTE, Label: LABEL_0\n",
            "Word: ZLETSS, Label: LABEL_0\n",
            "Word: Name, Label: LABEL_0\n",
            "Word: IMRAN, Label: LABEL_0\n",
            "Word: SAJID, Label: LABEL_0\n",
            "Word: HUSSAIN, Label: LABEL_0\n",
            "Word: SABIR, Label: LABEL_0\n",
            "Word: ja, Label: LABEL_0\n",
            "Word: Pen, Label: LABEL_0\n",
            "Word: Y, Label: LABEL_0\n",
            "Word: ttt, Label: LABEL_0\n",
            "Word: SSAEZZ, Label: LABEL_0\n",
            "Word: ”, Label: LABEL_0\n",
            "Word: nationauty, Label: LABEL_1\n",
            "Word: PAKISTANI, Label: LABEL_2\n",
            "Word: -, Label: LABEL_2\n",
            "Word: IDOMN73303848, Label: LABEL_2\n",
            "Word: <, Label: LABEL_2\n",
            "Word: 0, Label: LABEL_2\n",
            "Word: <, Label: LABEL_2\n",
            "Word: <, Label: LABEL_2\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: K, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: cKcccsee, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: 8205122M2405067PAK, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: Kccc2, Label: LABEL_0\n",
            "Word: IMRAN, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: SAJ, Label: LABEL_0\n",
            "Word: ID, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: HUSSAINK, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: ccc, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: [SEP], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "\n",
            "Extracted Entities:\n",
            "Entity: 8? fit ft eke \\ SULTANATE OF OMAN RESIDENT CARD 88C001C3103 12478 CIVIL NUMBER oye ee Kyle : 73303848 olla oe EE EXPIRY. DATE 06 / 05 / 2004 Haw gat signavune yx DATE - GF BIRTH 01 / 05 / 1982 shyt ' ~. “ Ae hen SLU GIS HE Sno shar kat OI yal Yl Osh OU ope gi gl steel yy a eagle Spite Oya at VEHICLE ORIVING LICENCE ROYAL OMAR POLICE CLASS D. C. OF CLVIL STATUS NOTE ZLETSS Name IMRAN SAJID HUS, Label: LABEL_0\n",
            "Entity: ##SA, Label: LABEL_1\n",
            "Entity: ##IN SABIR ja Pen Y ttt SSA, Label: LABEL_0\n",
            "Entity: ##EZZ, Label: LABEL_1\n",
            "Entity: ”, Label: LABEL_0\n",
            "Entity: nationauty, Label: LABEL_1\n",
            "Entity: PAKISTANI - IDOMN73303848 < 0 < <, Label: LABEL_2\n",
            "Entity: < < < < K < cKcccsee < 8205122M2405067PAK < < < < < < < < Kccc2 IMRAN < SAJ ID < HUSSAINK < < < < < < < ccc <, Label: LABEL_0\n",
            "\n",
            "Extracted CIVIL_NUMBER:\n",
            "\n",
            "\n",
            "Extracted DATE_OF_BIRTH:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "#model_path = './results'  # Update this with your model path\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example text for inference\n",
        "example_text = \"\"\"\n",
        "8? fit ft eke \\\\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "88C001C3103 12478\n",
        "\n",
        "CIVIL NUMBER oye\n",
        "ee Kyle : 73303848 olla\n",
        "oe EE EXPIRY. DATE 06/05/2004 Haw gat\n",
        "signavune yx DATE OF BIRTH 01/05/1982 shyt\n",
        "' ~ . “Ae\n",
        "hen SLU GIS\n",
        "HE Sno shar kat OI yal Yl\n",
        "Osh OU ope gi gl\n",
        "steel yy a eagle Spite Oya at\n",
        "\n",
        "VEHICLE ORIVING LICENCE\n",
        "\n",
        "ROYAL OMAR POLICE CLASS\n",
        "D.C. OF CLVIL STATUS\n",
        "\n",
        "NOTE\n",
        "ZLETSS Name IMRAN SAJID HUSSAIN SABIR\n",
        "\n",
        "ja Pen Y ttt\n",
        "SSAEZZ” nationauty PAKISTANI -\n",
        "\n",
        "IDOMN73303848<0<<<<<<K<cKcccsee<\n",
        "8205122M2405067PAK<<<<<<<<Kccc2\n",
        "IMRAN<SAJ ID<HUSSAINK<<<<<<<ccc<\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(example_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Convert predictions to labels\n",
        "label_list = model.config.id2label\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "predicted_labels = [label_list[pred.item()] for pred in predictions[0]]\n",
        "\n",
        "# Function to merge tokens\n",
        "def merge_tokens(tokens, labels):\n",
        "    words, merged_labels = [], []\n",
        "    current_word, current_label = '', ''\n",
        "\n",
        "    for token, label in zip(tokens, labels):\n",
        "        if token.startswith('##'):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            if current_word:\n",
        "                words.append(current_word)\n",
        "                merged_labels.append(current_label)\n",
        "            current_word = token\n",
        "            current_label = label\n",
        "\n",
        "    if current_word:  # Append the last token\n",
        "        words.append(current_word)\n",
        "        merged_labels.append(current_label)\n",
        "\n",
        "    return words, merged_labels\n",
        "\n",
        "# Merge tokens and labels\n",
        "words, labels = merge_tokens(tokens, predicted_labels)\n",
        "\n",
        "# Display the tokens and their predicted labels\n",
        "print(\"Token\\t\\tPrediction\")\n",
        "for token, label in zip(tokens, predicted_labels):\n",
        "    if token not in tokenizer.all_special_tokens:\n",
        "        print(f\"{token}\\t\\t{label}\")\n",
        "\n",
        "# Display the merged entities\n",
        "print(\"\\nMerged Entities:\")\n",
        "for word, label in zip(words, labels):\n",
        "    print(f\"Word: {word}, Label: {label}\")\n",
        "\n",
        "# Extract entities using the pipeline\n",
        "result = nlp(example_text)\n",
        "print(\"\\nExtracted Entities:\")\n",
        "for entity in result:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}\")\n",
        "\n",
        "# Function to clean entity tokens\n",
        "def clean_entity(tokens):\n",
        "    return \" \".join(tokens).replace(\" ##\", \"\")\n",
        "\n",
        "# Extract specific entities\n",
        "civil_number = []\n",
        "date_of_birth = []\n",
        "\n",
        "for word, label in zip(words, labels):\n",
        "    if 'CIVIL_NUMBER' in label:\n",
        "        civil_number.append(word)\n",
        "    elif 'DATE_OF_BIRTH' in label:\n",
        "        date_of_birth.append(word)\n",
        "\n",
        "# Clean and print extracted CIVIL_NUMBER and DATE_OF_BIRTH\n",
        "cleaned_civil_number = clean_entity(civil_number)\n",
        "cleaned_date_of_birth = clean_entity(date_of_birth)\n",
        "\n",
        "print(\"\\nExtracted CIVIL_NUMBER:\")\n",
        "print(cleaned_civil_number)\n",
        "\n",
        "print(\"\\nExtracted DATE_OF_BIRTH:\")\n",
        "print(cleaned_date_of_birth)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUBjitxJ5z_k",
        "outputId": "f1839200-511c-4911-c4d1-0ec3838f17b9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tPrediction\n",
            "8\t\tLABEL_0\n",
            "?\t\tLABEL_0\n",
            "fit\t\tLABEL_0\n",
            "ft\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##ke\t\tLABEL_0\n",
            "\\\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "##LT\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##N\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##ES\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##T\t\tLABEL_0\n",
            "CA\t\tLABEL_0\n",
            "##RD\t\tLABEL_0\n",
            "88\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##00\t\tLABEL_0\n",
            "##1\t\tLABEL_0\n",
            "##C\t\tLABEL_0\n",
            "##31\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##3\t\tLABEL_0\n",
            "124\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##8\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "N\t\tLABEL_0\n",
            "##UM\t\tLABEL_0\n",
            "##BE\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##ye\t\tLABEL_0\n",
            "e\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "Kyle\t\tLABEL_0\n",
            ":\t\tLABEL_0\n",
            "73\t\tLABEL_0\n",
            "##30\t\tLABEL_0\n",
            "##38\t\tLABEL_0\n",
            "##48\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##lla\t\tLABEL_0\n",
            "o\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "E\t\tLABEL_0\n",
            "##X\t\tLABEL_0\n",
            "##PI\t\tLABEL_0\n",
            "##R\t\tLABEL_1\n",
            "##Y\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "06\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "2004\t\tLABEL_0\n",
            "Ha\t\tLABEL_0\n",
            "##w\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##at\t\tLABEL_0\n",
            "sign\t\tLABEL_0\n",
            "##av\t\tLABEL_0\n",
            "##une\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##x\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "B\t\tLABEL_0\n",
            "##IR\t\tLABEL_0\n",
            "##TH\t\tLABEL_0\n",
            "01\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "05\t\tLABEL_0\n",
            "/\t\tLABEL_0\n",
            "1982\t\tLABEL_0\n",
            "shy\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "'\t\tLABEL_0\n",
            "~\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "“\t\tLABEL_0\n",
            "A\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "he\t\tLABEL_0\n",
            "##n\t\tLABEL_0\n",
            "SL\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "G\t\tLABEL_0\n",
            "##IS\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##no\t\tLABEL_0\n",
            "s\t\tLABEL_0\n",
            "##har\t\tLABEL_0\n",
            "ka\t\tLABEL_0\n",
            "##t\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "ya\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##sh\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##U\t\tLABEL_0\n",
            "op\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##i\t\tLABEL_0\n",
            "g\t\tLABEL_0\n",
            "##l\t\tLABEL_0\n",
            "steel\t\tLABEL_0\n",
            "y\t\tLABEL_0\n",
            "##y\t\tLABEL_0\n",
            "a\t\tLABEL_0\n",
            "eagle\t\tLABEL_0\n",
            "S\t\tLABEL_0\n",
            "##pit\t\tLABEL_0\n",
            "##e\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##ya\t\tLABEL_0\n",
            "at\t\tLABEL_0\n",
            "V\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "##H\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "OR\t\tLABEL_0\n",
            "##I\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##NG\t\tLABEL_0\n",
            "L\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##EN\t\tLABEL_0\n",
            "##CE\t\tLABEL_0\n",
            "R\t\tLABEL_0\n",
            "##O\t\tLABEL_0\n",
            "##Y\t\tLABEL_0\n",
            "##AL\t\tLABEL_0\n",
            "O\t\tLABEL_0\n",
            "##MA\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "P\t\tLABEL_0\n",
            "##OL\t\tLABEL_0\n",
            "##IC\t\tLABEL_0\n",
            "##E\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##LA\t\tLABEL_0\n",
            "##SS\t\tLABEL_0\n",
            "D\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            ".\t\tLABEL_0\n",
            "OF\t\tLABEL_0\n",
            "C\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "##VI\t\tLABEL_0\n",
            "##L\t\tLABEL_0\n",
            "ST\t\tLABEL_0\n",
            "##AT\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "NO\t\tLABEL_0\n",
            "##TE\t\tLABEL_0\n",
            "Z\t\tLABEL_0\n",
            "##LE\t\tLABEL_0\n",
            "##TS\t\tLABEL_0\n",
            "##S\t\tLABEL_0\n",
            "Name\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "##ID\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_1\n",
            "##IN\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##BI\t\tLABEL_0\n",
            "##R\t\tLABEL_0\n",
            "j\t\tLABEL_0\n",
            "##a\t\tLABEL_0\n",
            "Pen\t\tLABEL_0\n",
            "Y\t\tLABEL_0\n",
            "t\t\tLABEL_0\n",
            "##tt\t\tLABEL_0\n",
            "SS\t\tLABEL_0\n",
            "##A\t\tLABEL_0\n",
            "##E\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "##Z\t\tLABEL_1\n",
            "”\t\tLABEL_0\n",
            "nation\t\tLABEL_1\n",
            "##aut\t\tLABEL_1\n",
            "##y\t\tLABEL_1\n",
            "PA\t\tLABEL_2\n",
            "##K\t\tLABEL_2\n",
            "##IS\t\tLABEL_2\n",
            "##TA\t\tLABEL_2\n",
            "##NI\t\tLABEL_2\n",
            "-\t\tLABEL_2\n",
            "ID\t\tLABEL_2\n",
            "##OM\t\tLABEL_2\n",
            "##N\t\tLABEL_2\n",
            "##7\t\tLABEL_2\n",
            "##33\t\tLABEL_2\n",
            "##0\t\tLABEL_2\n",
            "##38\t\tLABEL_2\n",
            "##48\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "0\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_2\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "c\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##cs\t\tLABEL_0\n",
            "##ee\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "82\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##51\t\tLABEL_0\n",
            "##22\t\tLABEL_0\n",
            "##M\t\tLABEL_0\n",
            "##24\t\tLABEL_0\n",
            "##0\t\tLABEL_0\n",
            "##50\t\tLABEL_0\n",
            "##6\t\tLABEL_0\n",
            "##7\t\tLABEL_0\n",
            "##PA\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "K\t\tLABEL_0\n",
            "##cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "##2\t\tLABEL_0\n",
            "I\t\tLABEL_0\n",
            "##MR\t\tLABEL_0\n",
            "##AN\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "SA\t\tLABEL_0\n",
            "##J\t\tLABEL_0\n",
            "ID\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "H\t\tLABEL_0\n",
            "##US\t\tLABEL_0\n",
            "##SA\t\tLABEL_0\n",
            "##IN\t\tLABEL_0\n",
            "##K\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "cc\t\tLABEL_0\n",
            "##c\t\tLABEL_0\n",
            "<\t\tLABEL_0\n",
            "\n",
            "Merged Entities:\n",
            "Word: [CLS], Label: LABEL_0\n",
            "Word: 8, Label: LABEL_0\n",
            "Word: ?, Label: LABEL_0\n",
            "Word: fit, Label: LABEL_0\n",
            "Word: ft, Label: LABEL_0\n",
            "Word: eke, Label: LABEL_0\n",
            "Word: \\, Label: LABEL_0\n",
            "Word: SULTANATE, Label: LABEL_0\n",
            "Word: OF, Label: LABEL_0\n",
            "Word: OMAN, Label: LABEL_0\n",
            "Word: RESIDENT, Label: LABEL_0\n",
            "Word: CARD, Label: LABEL_0\n",
            "Word: 88C001C3103, Label: LABEL_0\n",
            "Word: 12478, Label: LABEL_0\n",
            "Word: CIVIL, Label: LABEL_0\n",
            "Word: NUMBER, Label: LABEL_0\n",
            "Word: oye, Label: LABEL_0\n",
            "Word: ee, Label: LABEL_0\n",
            "Word: Kyle, Label: LABEL_0\n",
            "Word: :, Label: LABEL_0\n",
            "Word: 73303848, Label: LABEL_0\n",
            "Word: olla, Label: LABEL_0\n",
            "Word: oe, Label: LABEL_0\n",
            "Word: EE, Label: LABEL_0\n",
            "Word: EXPIRY, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: DATE, Label: LABEL_0\n",
            "Word: 06, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 05, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 2004, Label: LABEL_0\n",
            "Word: Haw, Label: LABEL_0\n",
            "Word: gat, Label: LABEL_0\n",
            "Word: signavune, Label: LABEL_0\n",
            "Word: yx, Label: LABEL_0\n",
            "Word: DATE, Label: LABEL_0\n",
            "Word: OF, Label: LABEL_0\n",
            "Word: BIRTH, Label: LABEL_0\n",
            "Word: 01, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 05, Label: LABEL_0\n",
            "Word: /, Label: LABEL_0\n",
            "Word: 1982, Label: LABEL_0\n",
            "Word: shyt, Label: LABEL_0\n",
            "Word: ', Label: LABEL_0\n",
            "Word: ~, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: “, Label: LABEL_0\n",
            "Word: Ae, Label: LABEL_0\n",
            "Word: hen, Label: LABEL_0\n",
            "Word: SLU, Label: LABEL_0\n",
            "Word: GIS, Label: LABEL_0\n",
            "Word: HE, Label: LABEL_0\n",
            "Word: Sno, Label: LABEL_0\n",
            "Word: shar, Label: LABEL_0\n",
            "Word: kat, Label: LABEL_0\n",
            "Word: OI, Label: LABEL_0\n",
            "Word: yal, Label: LABEL_0\n",
            "Word: Yl, Label: LABEL_0\n",
            "Word: Osh, Label: LABEL_0\n",
            "Word: OU, Label: LABEL_0\n",
            "Word: ope, Label: LABEL_0\n",
            "Word: gi, Label: LABEL_0\n",
            "Word: gl, Label: LABEL_0\n",
            "Word: steel, Label: LABEL_0\n",
            "Word: yy, Label: LABEL_0\n",
            "Word: a, Label: LABEL_0\n",
            "Word: eagle, Label: LABEL_0\n",
            "Word: Spite, Label: LABEL_0\n",
            "Word: Oya, Label: LABEL_0\n",
            "Word: at, Label: LABEL_0\n",
            "Word: VEHICLE, Label: LABEL_0\n",
            "Word: ORIVING, Label: LABEL_0\n",
            "Word: LICENCE, Label: LABEL_0\n",
            "Word: ROYAL, Label: LABEL_0\n",
            "Word: OMAR, Label: LABEL_0\n",
            "Word: POLICE, Label: LABEL_0\n",
            "Word: CLASS, Label: LABEL_0\n",
            "Word: D, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: C, Label: LABEL_0\n",
            "Word: ., Label: LABEL_0\n",
            "Word: OF, Label: LABEL_0\n",
            "Word: CLVIL, Label: LABEL_0\n",
            "Word: STATUS, Label: LABEL_0\n",
            "Word: NOTE, Label: LABEL_0\n",
            "Word: ZLETSS, Label: LABEL_0\n",
            "Word: Name, Label: LABEL_0\n",
            "Word: IMRAN, Label: LABEL_0\n",
            "Word: SAJID, Label: LABEL_0\n",
            "Word: HUSSAIN, Label: LABEL_0\n",
            "Word: SABIR, Label: LABEL_0\n",
            "Word: ja, Label: LABEL_0\n",
            "Word: Pen, Label: LABEL_0\n",
            "Word: Y, Label: LABEL_0\n",
            "Word: ttt, Label: LABEL_0\n",
            "Word: SSAEZZ, Label: LABEL_0\n",
            "Word: ”, Label: LABEL_0\n",
            "Word: nationauty, Label: LABEL_1\n",
            "Word: PAKISTANI, Label: LABEL_2\n",
            "Word: -, Label: LABEL_2\n",
            "Word: IDOMN73303848, Label: LABEL_2\n",
            "Word: <, Label: LABEL_2\n",
            "Word: 0, Label: LABEL_2\n",
            "Word: <, Label: LABEL_2\n",
            "Word: <, Label: LABEL_2\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: K, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: cKcccsee, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: 8205122M2405067PAK, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: Kccc2, Label: LABEL_0\n",
            "Word: IMRAN, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: SAJ, Label: LABEL_0\n",
            "Word: ID, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: HUSSAINK, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: ccc, Label: LABEL_0\n",
            "Word: <, Label: LABEL_0\n",
            "Word: [SEP], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_2\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "Word: [PAD], Label: LABEL_0\n",
            "\n",
            "Extracted Entities:\n",
            "Entity: 8? fit ft eke \\ SULTANATE OF OMAN RESIDENT CARD 88C001C3103 12478 CIVIL NUMBER oye ee Kyle : 73303848 olla oe EE EXPI, Label: LABEL_0\n",
            "Entity: ##R, Label: LABEL_1\n",
            "Entity: ##Y. DATE 06 / 05 / 2004 Haw gat signavune yx DATE OF BIRTH 01 / 05 / 1982 shyt ' ~. “ Ae hen SLU GIS HE Sno shar kat OI yal Yl Osh OU ope gi gl steel yy a eagle Spite Oya at VEHICLE ORIVING LICENCE ROYAL OMAR POLICE CLASS D. C. OF CLVIL STATUS NOTE ZLETSS Name IMRAN SAJID HUS, Label: LABEL_0\n",
            "Entity: ##SA, Label: LABEL_1\n",
            "Entity: ##IN SABIR ja Pen Y ttt SSA, Label: LABEL_0\n",
            "Entity: ##EZZ, Label: LABEL_1\n",
            "Entity: ”, Label: LABEL_0\n",
            "Entity: nationauty, Label: LABEL_1\n",
            "Entity: PAKISTANI - IDOMN73303848 < 0 < <, Label: LABEL_2\n",
            "Entity: < < < < K < cKcccsee < 8205122M2405067PAK < < < < < < < < Kccc2 IMRAN < SAJ ID < HUSSAINK < < < < < < < ccc <, Label: LABEL_0\n",
            "\n",
            "Extracted CIVIL_NUMBER:\n",
            "\n",
            "\n",
            "Extracted DATE_OF_BIRTH:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "3F61AjW64efk",
        "outputId": "d22ad177-a4a1-4a6c-b4f7-276a5649bb90"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Sample Data Date of Birth  \\\n",
              "0      XDpsFRDjkr \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    26/07/1985   \n",
              "1      bKURhFJnWI \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    04/03/1951   \n",
              "2      hOJNkhdSCj \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    07/01/1962   \n",
              "3      zGyBHwCFoi \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    04/05/1953   \n",
              "4      jJJMpNUhWo \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    20/12/1973   \n",
              "...                                                  ...           ...   \n",
              "19995  noXlvfOroG \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    07/07/1996   \n",
              "19996  f zKgKlEWi \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    05/02/1963   \n",
              "19997  iYfvVNMdho \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    24/01/1989   \n",
              "19998  EqzxJjIEdg \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    21/02/1964   \n",
              "19999  YOzFBZMDhz \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...    31/10/1955   \n",
              "\n",
              "       Civil Number                                             tokens  \\\n",
              "0          83814105  [XDpsFRDjkr, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "1          79787460  [bKURhFJnWI, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "2          94486471  [hOJNkhdSCj, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "3          92850968  [zGyBHwCFoi, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "4          92951996  [jJJMpNUhWo, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "...             ...                                                ...   \n",
              "19995      13930207  [noXlvfOroG, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "19996        432697  [f, zKgKlEWi, \\, SULTANATE, OF, OMAN, RESIDENT...   \n",
              "19997       1219671  [iYfvVNMdho, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "19998      45463890  [EqzxJjIEdg, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "19999      74035018  [YOzFBZMDhz, \\, SULTANATE, OF, OMAN, RESIDENT,...   \n",
              "\n",
              "                                                ner_tags  \n",
              "0      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "1      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "...                                                  ...  \n",
              "19995  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "19996  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "19997  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "19998  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "19999  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "\n",
              "[20000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-132b858b-ce3d-467a-a8e8-9b6a52d3513a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample Data</th>\n",
              "      <th>Date of Birth</th>\n",
              "      <th>Civil Number</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XDpsFRDjkr \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>26/07/1985</td>\n",
              "      <td>83814105</td>\n",
              "      <td>[XDpsFRDjkr, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bKURhFJnWI \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>04/03/1951</td>\n",
              "      <td>79787460</td>\n",
              "      <td>[bKURhFJnWI, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hOJNkhdSCj \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>07/01/1962</td>\n",
              "      <td>94486471</td>\n",
              "      <td>[hOJNkhdSCj, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>zGyBHwCFoi \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>04/05/1953</td>\n",
              "      <td>92850968</td>\n",
              "      <td>[zGyBHwCFoi, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jJJMpNUhWo \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>20/12/1973</td>\n",
              "      <td>92951996</td>\n",
              "      <td>[jJJMpNUhWo, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>noXlvfOroG \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>07/07/1996</td>\n",
              "      <td>13930207</td>\n",
              "      <td>[noXlvfOroG, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>f zKgKlEWi \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>05/02/1963</td>\n",
              "      <td>432697</td>\n",
              "      <td>[f, zKgKlEWi, \\, SULTANATE, OF, OMAN, RESIDENT...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>iYfvVNMdho \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>24/01/1989</td>\n",
              "      <td>1219671</td>\n",
              "      <td>[iYfvVNMdho, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>EqzxJjIEdg \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>21/02/1964</td>\n",
              "      <td>45463890</td>\n",
              "      <td>[EqzxJjIEdg, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>YOzFBZMDhz \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...</td>\n",
              "      <td>31/10/1955</td>\n",
              "      <td>74035018</td>\n",
              "      <td>[YOzFBZMDhz, \\, SULTANATE, OF, OMAN, RESIDENT,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-132b858b-ce3d-467a-a8e8-9b6a52d3513a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-132b858b-ce3d-467a-a8e8-9b6a52d3513a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-132b858b-ce3d-467a-a8e8-9b6a52d3513a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a6fff59-084b-443a-90cb-b19f9a452ecf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a6fff59-084b-443a-90cb-b19f9a452ecf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a6fff59-084b-443a-90cb-b19f9a452ecf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_23897d2a-0b41-4dc6-8007-a337420ea8cb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_23897d2a-0b41-4dc6-8007-a337420ea8cb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"Sample Data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"zUfvmZGhvb \\\\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nCARD\\n\\n2XTPSLBFX31D 12478\\n\\nCIVIL NUMBER Nik\\nee Kyle : 17341101 tHCY\\noe EE EXPIRY. DATE 19/06/2030 CgNoZ\\nsignavune xL DATE-GF BIRTH 18/10/1956 jTCq\\n' ~ . \\u201cAe\\nhen SLU GIS\\nHE sCo shar kat WT yal Yl\\nOsh dq ope gi IA\\nsteel nP a eagle Spite Lu at\\n\\nVEHICLE ORIVING LICENCE\\n\\nROYAL OMAR POLICE CLASS\\nD.C. OF CLVIL STATUS\\n\\nNOTE\\nZLETSS Name Ahmed Sabir\\n\\nja Pen Y ttt\\nSSAEZZ\\u201d nationauty PAKISTANI -\\n\\nIDOMN17341101<0<<<<<<K<cKcccsee<\\n1019562M0620307PAK<<<<<<<<Kccc2\\nAhmed<Sabir<<<<<<<<<ccc<\",\n          \"IHCAmWrGJQ \\\\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nCARD\\n\\nF2GYO3VZP0FI 12478\\n\\nCIVIL NUMBER iiQ\\nee Kyle : 76145170 dWUQ\\noe EE EXPIRY. DATE 04/09/2024 IXFsq\\nsignavune EK DATE-GF BIRTH 29/06/1976 Wzkq\\n' ~ . \\u201cAe\\nhen SLU GIS\\nHE mMF shar kat gI yal Yl\\nOsh Dt ope gi fF\\nsteel BY a eagle Spite Xs at\\n\\nVEHICLE ORIVING LICENCE\\n\\nROYAL OMAR POLICE CLASS\\nD.C. OF CLVIL STATUS\\n\\nNOTE\\nZLETSS Name Khalid Hussain\\n\\nja Pen Y ttt\\nSSAEZZ\\u201d nationauty PAKISTANI -\\n\\nIDOMN76145170<0<<<<<<K<cKcccsee<\\n0619762M0920247PAK<<<<<<<<Kccc2\\nKhalid<Hussain<<<<<<<<<ccc<\",\n          \"UcuywfAmrp \\\\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nCARD\\n\\nB6H6912QHVZY 12478\\n\\nCIVIL NUMBER pcG\\nee Kyle : 13674559 L Mo\\noe EE EXPIRY. DATE 05/04/2026 UPcUO\\nsignavune lu DATE-GF BIRTH 22/12/1997 nUnw\\n' ~ . \\u201cAe\\nhen SLU GIS\\nHE lwk shar kat wC yal Yl\\nOsh qB ope gi  Z\\nsteel OQ a eagle Spite lp at\\n\\nVEHICLE ORIVING LICENCE\\n\\nROYAL OMAR POLICE CLASS\\nD.C. OF CLVIL STATUS\\n\\nNOTE\\nZLETSS Name Hassan Khan\\n\\nja Pen Y ttt\\nSSAEZZ\\u201d nationauty PAKISTANI -\\n\\nIDOMN13674559<0<<<<<<K<cKcccsee<\\n1219972M0420267PAK<<<<<<<<Kccc2\\nHassan<Khan<<<<<<<<<ccc<\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date of Birth\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 12283,\n        \"samples\": [\n          \"15/02/1985\",\n          \"17/09/1975\",\n          \"06/11/1969\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Civil Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28754714,\n        \"min\": 3294,\n        \"max\": 99997424,\n        \"num_unique_values\": 19999,\n        \"samples\": [\n          17341101,\n          76145170,\n          13674559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('resident_card_data_full.csv')\n",
        "\n",
        "# Inspect data\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpwtoGKjC3YM",
        "outputId": "3bd45b67-6552-4d50-a296-17272ce396ef"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Sample Data Date of Birth  \\\n",
            "0  8? fit ft eke \\\\nSULTANATE OF OMAN\\n\\nRESIDENT...    14/02/1968   \n",
            "1  8? fit ft eke \\\\nSULTANATE OF OMAN\\n\\nRESIDENT...    06/08/2000   \n",
            "2  8? fit ft eke \\\\nSULTANATE OF OMAN\\n\\nRESIDENT...    28/09/1992   \n",
            "3  8? fit ft eke \\\\nSULTANATE OF OMAN\\n\\nRESIDENT...    12/09/1977   \n",
            "4  8? fit ft eke \\\\nSULTANATE OF OMAN\\n\\nRESIDENT...    21/08/1991   \n",
            "\n",
            "   Civil Number  \n",
            "0      53134749  \n",
            "1      34770676  \n",
            "2      39148038  \n",
            "3      39699161  \n",
            "4      70722907  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize sample_data\n",
        "df['input_ids'] = df['Sample Data'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))\n",
        "\n",
        "# Create target sequences\n",
        "df['target'] = df.apply(lambda x: f\"DOB: {x['Date of Birth']} CIVIL: {x['Civil Number']}\", axis=1)\n",
        "\n",
        "# Tokenize target sequences\n",
        "df['target_ids'] = df['target'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=50, truncation=True))\n",
        "\n",
        "# Split the data\n",
        "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q9MeXpFC_yd",
        "outputId": "6a525d09-c724-4d0d-a6c3-a119c452626e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "# Load a pre-trained BERT model\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased')\n",
        "\n",
        "# Set special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Set training parameters\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "model.config.max_length = 50\n",
        "model.config.no_repeat_ngram_size = 2\n",
        "model.config.early_stopping = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0DZJvsDGXz",
        "outputId": "5a954f69-3049-41a8-96cd-a5df1cae2bcb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, EncoderDecoderModel, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "# Load and inspect data\n",
        "df = pd.read_csv('corrected_complex_sample_data_20000_samples.csv')\n",
        "print(df.head())\n",
        "\n",
        "# Ensure there are no missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize sample_data with padding and truncation\n",
        "df['input_ids'] = df['sample_data'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True, padding='max_length'))\n",
        "\n",
        "# Create target sequences\n",
        "df['target'] = df.apply(lambda x: f\"DOB: {x['CIVIL NUMBER']} CIVIL: {x['CIVIL NUMBER']}\", axis=1)\n",
        "\n",
        "# Tokenize target sequences with padding and truncation\n",
        "df['target_ids'] = df['target'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=50, truncation=True, padding='max_length'))\n",
        "\n",
        "# Convert to dataset format suitable for Seq2SeqTrainer\n",
        "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.input_ids = data['input_ids'].tolist()\n",
        "        self.target_ids = data['target_ids'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.target_ids[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "train_dataset = CustomDataset(train_data)\n",
        "val_dataset = CustomDataset(val_data)\n",
        "\n",
        "# Load a pre-trained BERT model\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased')\n",
        "\n",
        "# Set special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Set training parameters\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "model.config.max_length = 50\n",
        "model.config.no_repeat_ngram_size = 2\n",
        "model.config.early_stopping = True\n",
        "\n",
        "# Define training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True\n",
        ")\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "print(f\"Validation Loss: {results['eval_loss']}\")\n",
        "\n",
        "# Function to predict\n",
        "#def predict(sample_data):\n",
        "#    inputs = tokenizer.encode(sample_data, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "#    outputs = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "##    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        " #   return prediction\n",
        "\n",
        "# Example prediction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2e_61k7BDLen",
        "outputId": "4615e736-116e-458b-b73d-0d7caa03d936"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CIVIL NUMBER DATE OF BIRTH  \\\n",
            "0    8478170552    29/10/1995   \n",
            "1    8642905433    28/07/2001   \n",
            "2    3687239949    24/05/1986   \n",
            "3    4556950879    09/05/1993   \n",
            "4    8814111616    22/09/1987   \n",
            "\n",
            "                                         sample_data  \n",
            "0  3pfe1L3JVY \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...  \n",
            "1  3pfe1L3JVY \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...  \n",
            "2  3pfe1L3JVY \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...  \n",
            "3  3pfe1L3JVY \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...  \n",
            "4  3pfe1L3JVY \\\\nSULTANATE OF OMAN\\n\\nRESIDENT\\nC...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12000/12000 38:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.383400</td>\n",
              "      <td>0.706379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.010900</td>\n",
              "      <td>0.400964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.496927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'early_stopping': True, 'no_repeat_ngram_size': 2}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 00:46]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4969269633293152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = EncoderDecoderModel.from_pretrained('./results/checkpoint-12000')  # Adjust path as needed\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulrPwVejN9ri",
        "outputId": "aa312d25-77ab-470f-b5c2-09d247dc5466"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoderModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoder): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prediction(inputs):\n",
        "    # Generate prediction\n",
        "    outputs = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "LmweLCbrOWY_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prediction(inputs):\n",
        "    # Generate prediction\n",
        "    outputs = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "slEWNpltOZVR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_output(outputs):\n",
        "    # Decode the output tokens to text\n",
        "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "sNQa52xsOcGX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sample_data):\n",
        "    inputs = prepare_input(sample_data)\n",
        "    outputs = generate_prediction(inputs)\n",
        "    prediction = decode_output(outputs)\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "uAck1Xb4Oe5z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sample_data'].iloc[5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "OmcmQQO4qdnZ",
        "outputId": "d2bad5f8-b154-4166-be7b-5979f5cc2905"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-81d6235db92d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input text\n",
        "sample_data = df['sample_data'].iloc[188]\n",
        "\n",
        "# Make prediction\n",
        "prediction = predict(sample_data)\n",
        "\n",
        "print(f\"Sample Data: {sample_data}\")\n",
        "print(f\"Prediction: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-bfLKHkOh_c",
        "outputId": "c378c1a5-3ae6-4fa7-b6ab-e00d40226dab"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data: 7uRFLTnhA  \\\n",
            "SULTANATE OF OMAN\n",
            "\n",
            "RESIDENT\n",
            "CARD\n",
            "\n",
            "2DSSWWHSEAHU zWsBV\n",
            "\n",
            "\n",
            "\n",
            "CIVIL NUMBER L83\n",
            "ee Kyle :  4278059 Myjf\n",
            "oe EE EXPIRY. DATE 25/08/2030 J2AWYm\n",
            "signavune yx DATE OF  BIRTH 06/02/1963 A5zN\n",
            "' ~ . ML\n",
            "hen kml\n",
            "HE QXA1g\n",
            "Osh lwly6\n",
            "steel yy a eagle 1h4QX\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "VEHICLE YsDBBIm\n",
            "\n",
            "ROYAL DZFEu CLASS\n",
            "D.C. OF iaxm STATUS\n",
            "\n",
            "\n",
            "NOTE\n",
            "ZLETSS Name Omar Yasir Hussain\n",
            "\n",
            "ja Pen Y ttt\n",
            "SSAEZZ” nationauty Sri Lankan -\n",
            "\n",
            "\n",
            "IDOMN4278059<<<<<K<cKcccsee<\n",
            "0219632M0320257SRI<<<<<<<<Kccc2\n",
            "Omar<Yasir<Hussain<<<<<<<<<ccc<\n",
            "Prediction: dob : 26 / 02 / 1963 civil : 4278059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['sample_data'].iloc[1800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzX-uC1B_lYT",
        "outputId": "22f7ef6a-1b2e-4b79-86b0-d10c4063230d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K0I6r8YF6M \\\n",
            "SULTANATE OF OMAN\n",
            "\n",
            "RESIDENT\n",
            "CARD\n",
            "\n",
            "BYKR8PUZVI1R II9k5\n",
            "\n",
            "\n",
            "\n",
            "CIVIL NUMBER jxD\n",
            "ee Kyle :  192394 Y4oo\n",
            "oe EE EXPIRY. DATE 20/05/2025 6fPe2j\n",
            "signavune yx DATE OF  BIRTH 09/09/1978 IK9v\n",
            "' ~ . Ac\n",
            "hen i7k\n",
            "HE ScKlI\n",
            "Osh zqMTW\n",
            "steel yy a eagle LfhEs\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "VEHICLE LdgNbjQ\n",
            "\n",
            "ROYAL 9waKF CLASS\n",
            "D.C. OF TLMi STATUS\n",
            "\n",
            "\n",
            "NOTE\n",
            "ZLETSS Name Khalid Rashid Malik\n",
            "\n",
            "ja Pen Y ttt\n",
            "SSAEZZ” nationauty Nepali -\n",
            "\n",
            "\n",
            "IDOMN192394<<<<<K<cKcccsee<\n",
            "0919782M0620307NEP<<<<<<<<Kccc2\n",
            "Khalid<Rashid<Malik<<<<<<<<<ccc<\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "1y_IWDmjOTh9"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"\n",
        "\n",
        "pariver \\\n",
        "SULTANATE OF OMAN\n",
        "\n",
        "RESIDENT\n",
        "CARD\n",
        "\n",
        "ksdjflsnknkdf\n",
        "\n",
        "\n",
        "CIVIL NUMBER jxD\n",
        "dfknd  12837434 Y4oo\n",
        "oe EE EXPIRY. DATE 20/05/2025 6fPe2j\n",
        "signavune yx DATE OF  BIRTH 10/10/1956 IK9v\n",
        "kdfnn 42\n",
        "3kdnkdf\n",
        "dfdfjdf\n",
        "dslksdf\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z4wdWXCr_9Ge"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_data = df['sample_data'].iloc[188]\n",
        "\n",
        "# Make prediction\n",
        "prediction = predict(text)\n",
        "\n",
        "print(f\"Sample Data: {text}\")\n",
        "print(f\"Prediction: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNYCKoR0AbzC",
        "outputId": "41b4cb55-50b4-4d82-e3da-ef5e4fa8fb02"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data: \n",
            "\n",
            "pariver SULTANATE OF OMAN\n",
            "\n",
            "RESIDENT\n",
            "CARD\n",
            "\n",
            "ksdjflsnknkdf\n",
            "\n",
            "\n",
            "CIVIL NUMBER jxD\n",
            "dfknd  12837434 Y4oo\n",
            "oe EE EXPIRY. DATE 20/05/2025 6fPe2j\n",
            "signavune yx DATE OF  BIRTH 10/10/1956 IK9v\n",
            "kdfnn 42\n",
            "3kdnkdf\n",
            "dfdfjdf\n",
            "dslksdf\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Prediction: dob : 30 / 10 / 1960 civil :37434\n"
          ]
        }
      ]
    }
  ]
}